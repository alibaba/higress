// Package rag æä¾›åŸºäºé˜¿é‡Œäº‘å®˜æ–¹ SDK çš„ RAG å®¢æˆ·ç«¯å®ç°
package rag

import (
	"fmt"
	"log"
	"sync"
	"time"

	bailian "github.com/alibabacloud-go/bailian-20231229/v2/client"
	openapi "github.com/alibabacloud-go/darabonba-openapi/v2/client"
	util "github.com/alibabacloud-go/tea-utils/v2/service"
	"github.com/alibabacloud-go/tea/tea"
)

// RAGQuery RAG æŸ¥è¯¢è¯·æ±‚
type RAGQuery struct {
	Query       string                 `json:"query"`        // æŸ¥è¯¢æ–‡æœ¬
	Scenario    string                 `json:"scenario"`     // åœºæ™¯æ ‡è¯†
	TopK        int                    `json:"top_k"`        // è¿”å›æ–‡æ¡£æ•°é‡
	ContextMode string                 `json:"context_mode"` // ä¸Šä¸‹æ–‡æ¨¡å¼
	Filters     map[string]interface{} `json:"filters"`      // è¿‡æ»¤æ¡ä»¶
}

// RAGResponse RAG æŸ¥è¯¢å“åº”
type RAGResponse struct {
	Documents []RAGDocument `json:"documents"` // æ£€ç´¢åˆ°çš„æ–‡æ¡£
	Latency   int64         `json:"latency"`   // æŸ¥è¯¢å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
}

// RAGDocument è¡¨ç¤ºä¸€ä¸ªæ£€ç´¢åˆ°çš„æ–‡æ¡£
type RAGDocument struct {
	Title      string   `json:"title"`      // æ–‡æ¡£æ ‡é¢˜
	Content    string   `json:"content"`    // æ–‡æ¡£å†…å®¹
	Source     string   `json:"source"`     // æ¥æºè·¯å¾„
	URL        string   `json:"url"`        // åœ¨çº¿é“¾æ¥
	Score      float64  `json:"score"`      // ç›¸å…³åº¦åˆ†æ•°
	Highlights []string `json:"highlights"` // é«˜äº®ç‰‡æ®µ
}

// RAGClient ä½¿ç”¨é˜¿é‡Œäº‘å®˜æ–¹ SDK çš„ RAG å®¢æˆ·ç«¯
type RAGClient struct {
	config *RAGConfig
	client *bailian.Client
	cache  *QueryCache
}

// NewRAGClient åˆ›å»ºåŸºäº SDK çš„ RAG å®¢æˆ·ç«¯
func NewRAGClient(config *RAGConfig) (*RAGClient, error) {
	// åˆ›å»º SDK é…ç½®
	sdkConfig := &openapi.Config{
		AccessKeyId:     tea.String(config.AccessKeyID),
		AccessKeySecret: tea.String(config.AccessKeySecret),
	}

	// è®¾ç½®ç«¯ç‚¹ï¼ˆé»˜è®¤ä¸ºåŒ—äº¬åŒºåŸŸï¼‰
	if config.Endpoint != "" {
		sdkConfig.Endpoint = tea.String(config.Endpoint)
	} else {
		sdkConfig.Endpoint = tea.String("bailian.cn-beijing.aliyuncs.com")
	}

	// åˆ›å»ºå®¢æˆ·ç«¯
	client, err := bailian.NewClient(sdkConfig)
	if err != nil {
		return nil, fmt.Errorf("failed to create Bailian SDK client: %w", err)
	}

	c := &RAGClient{
		config: config,
		client: client,
	}

	// åˆå§‹åŒ–ç¼“å­˜
	if config.EnableCache {
		c.cache = NewQueryCache(config.CacheMaxSize, time.Duration(config.CacheTTL)*time.Second)
	}

	return c, nil
}

// SearchWithCache æŸ¥è¯¢çŸ¥è¯†åº“ï¼ˆå¸¦ç¼“å­˜ï¼‰
func (c *RAGClient) SearchWithCache(query *RAGQuery) (*RAGResponse, error) {
	// æ£€æŸ¥ç¼“å­˜
	if c.cache != nil {
		cacheKey := c.buildCacheKey(query)
		if cached := c.cache.Get(cacheKey); cached != nil {
			if c.config.Debug {
				log.Printf("ğŸ¯ RAG cache hit: %s", query.Query)
			}
			return cached, nil
		}
	}

	// æ‰§è¡ŒæŸ¥è¯¢
	startTime := time.Now()
	resp, err := c.search(query)
	if err != nil {
		return nil, err
	}

	// è®°å½•å»¶è¿Ÿ
	resp.Latency = time.Since(startTime).Milliseconds()

	// ç¼“å­˜ç»“æœ
	if c.cache != nil {
		cacheKey := c.buildCacheKey(query)
		c.cache.Set(cacheKey, resp)
	}

	if c.config.Debug {
		log.Printf("âœ… RAG query completed: %s (latency: %dms, docs: %d)",
			query.Query, resp.Latency, len(resp.Documents))
	}

	return resp, nil
}

// search æ‰§è¡Œå®é™…çš„æŸ¥è¯¢ï¼ˆå¸¦é‡è¯•ï¼‰
func (c *RAGClient) search(query *RAGQuery) (*RAGResponse, error) {
	var lastErr error

	for attempt := 0; attempt <= c.config.MaxRetries; attempt++ {
		if attempt > 0 {
			// é‡è¯•å‰ç­‰å¾…
			time.Sleep(time.Duration(c.config.RetryDelay) * time.Second)
			log.Printf("ğŸ”„ Retrying RAG query (attempt %d/%d)", attempt, c.config.MaxRetries)
		}

		resp, err := c.doSearchSDK(query)
		if err == nil {
			return resp, nil
		}

		lastErr = err
	}

	return nil, fmt.Errorf("RAG query failed after %d retries: %w", c.config.MaxRetries, lastErr)
}

// doSearchSDK æ‰§è¡Œå•æ¬¡æŸ¥è¯¢ï¼ˆä½¿ç”¨ SDKï¼‰
func (c *RAGClient) doSearchSDK(query *RAGQuery) (*RAGResponse, error) {
	// æ„å»ºæ£€ç´¢è¯·æ±‚
	request := &bailian.RetrieveRequest{
		IndexId: tea.String(c.config.KnowledgeBaseID),
		Query:   tea.String(query.Query),
	}

	// è®¾ç½®å¯é€‰å‚æ•°
	if query.TopK > 0 {
		request.DenseSimilarityTopK = tea.Int32(int32(query.TopK))
	} else {
		request.DenseSimilarityTopK = tea.Int32(int32(c.config.DefaultTopK))
	}

	// å¯ç”¨é‡æ’åº
	request.EnableReranking = tea.Bool(true)

	// å‡†å¤‡è¯·æ±‚å¤´å’Œè¿è¡Œæ—¶é€‰é¡¹
	headers := make(map[string]*string)
	runtime := &util.RuntimeOptions{}

	// è°ƒç”¨ SDK æ£€ç´¢æ¥å£
	response, err := c.client.RetrieveWithOptions(
		tea.String(c.config.WorkspaceID),
		request,
		headers,
		runtime,
	)

	if err != nil {
		return nil, fmt.Errorf("SDK retrieve failed: %w", err)
	}

	// æ£€æŸ¥å“åº”
	if response == nil || response.Body == nil {
		return nil, fmt.Errorf("empty response from SDK")
	}

	if !tea.BoolValue(response.Body.Success) {
		return nil, fmt.Errorf("SDK returned Success=false, Code=%s, Message=%s",
			tea.StringValue(response.Body.Code),
			tea.StringValue(response.Body.Message))
	}

	// è½¬æ¢ä¸º RAGResponse
	ragResp := &RAGResponse{
		Documents: make([]RAGDocument, 0),
	}

	if response.Body.Data != nil && response.Body.Data.Nodes != nil {
		for _, node := range response.Body.Data.Nodes {
			if node == nil {
				continue
			}

			// è¿‡æ»¤ä½ç›¸å…³åº¦æ–‡æ¡£
			score := tea.Float64Value(node.Score)
			if score < c.config.SimilarityThreshold {
				continue
			}

			// ä» Metadata ä¸­æå–ä¿¡æ¯
			title := ""
			source := ""
			url := ""

			if node.Metadata != nil {
				// Metadata æ˜¯ interface{} ç±»å‹ï¼Œéœ€è¦å…ˆè½¬æ¢ä¸º map
				if meta, ok := node.Metadata.(map[string]interface{}); ok {
					if t, ok := meta["title"].(string); ok {
						title = t
					}
					if s, ok := meta["doc_name"].(string); ok {
						source = s
					}
					if u, ok := meta["file_path"].(string); ok {
						url = u
					}
				}
			}

			ragResp.Documents = append(ragResp.Documents, RAGDocument{
				Title:      title,
				Content:    tea.StringValue(node.Text),
				Source:     source,
				URL:        url,
				Score:      score,
				Highlights: []string{}, // SDK ä¸è¿”å› highlights
			})
		}
	}

	return ragResp, nil
}

// buildCacheKey æ„å»ºç¼“å­˜é”®
func (c *RAGClient) buildCacheKey(query *RAGQuery) string {
	return fmt.Sprintf("%s:%s:top%d:%s", query.Scenario, query.Query, query.TopK, query.ContextMode)
}

// QueryCache æŸ¥è¯¢ç¼“å­˜
type QueryCache struct {
	entries map[string]*CacheEntry
	mu      sync.RWMutex
	maxSize int
	ttl     time.Duration
}

// CacheEntry ç¼“å­˜æ¡ç›®
type CacheEntry struct {
	Response  *RAGResponse
	ExpiresAt time.Time
}

// NewQueryCache åˆ›å»ºæŸ¥è¯¢ç¼“å­˜
func NewQueryCache(maxSize int, ttl time.Duration) *QueryCache {
	cache := &QueryCache{
		entries: make(map[string]*CacheEntry),
		maxSize: maxSize,
		ttl:     ttl,
	}

	// å¯åŠ¨æ¸…ç†åç¨‹
	go cache.cleanupLoop()

	return cache
}

// Get è·å–ç¼“å­˜
func (c *QueryCache) Get(key string) *RAGResponse {
	c.mu.RLock()
	defer c.mu.RUnlock()

	entry, ok := c.entries[key]
	if !ok {
		return nil
	}

	// æ£€æŸ¥æ˜¯å¦è¿‡æœŸ
	if time.Now().After(entry.ExpiresAt) {
		return nil
	}

	return entry.Response
}

// Set è®¾ç½®ç¼“å­˜
func (c *QueryCache) Set(key string, resp *RAGResponse) {
	c.mu.Lock()
	defer c.mu.Unlock()

	// æ£€æŸ¥ç¼“å­˜å¤§å°
	if len(c.entries) >= c.maxSize {
		// ç®€å•çš„ LRUï¼šåˆ é™¤ç¬¬ä¸€ä¸ªæ¡ç›®
		for k := range c.entries {
			delete(c.entries, k)
			break
		}
	}

	c.entries[key] = &CacheEntry{
		Response:  resp,
		ExpiresAt: time.Now().Add(c.ttl),
	}
}

// cleanupLoop æ¸…ç†è¿‡æœŸç¼“å­˜
func (c *QueryCache) cleanupLoop() {
	ticker := time.NewTicker(5 * time.Minute)
	defer ticker.Stop()

	for range ticker.C {
		c.cleanup()
	}
}

// cleanup æ‰§è¡Œæ¸…ç†
func (c *QueryCache) cleanup() {
	c.mu.Lock()
	defer c.mu.Unlock()

	now := time.Now()
	for key, entry := range c.entries {
		if now.After(entry.ExpiresAt) {
			delete(c.entries, key)
		}
	}
}
