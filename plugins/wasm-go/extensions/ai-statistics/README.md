---
title: AIå¯è§‚æµ‹
keywords: [higress, AI, observability]
description: AIå¯è§‚æµ‹é…ç½®å‚è€ƒ
---

## ä»‹ç»

æä¾› AI å¯è§‚æµ‹åŸºç¡€èƒ½åŠ›ï¼ŒåŒ…æ‹¬ metric, log, traceï¼Œå…¶åéœ€æ¥ ai-proxy æ’ä»¶ï¼Œå¦‚æœä¸æ¥ ai-proxy æ’ä»¶çš„è¯ï¼Œåˆ™éœ€è¦ç”¨æˆ·è¿›è¡Œç›¸åº”é…ç½®æ‰å¯ç”Ÿæ•ˆã€‚

## è¿è¡Œå±æ€§

æ’ä»¶æ‰§è¡Œé˜¶æ®µï¼š`é»˜è®¤é˜¶æ®µ`
æ’ä»¶æ‰§è¡Œä¼˜å…ˆçº§ï¼š`200`

## é…ç½®è¯´æ˜

æ’ä»¶é»˜è®¤è¯·æ±‚ç¬¦åˆ openai åè®®æ ¼å¼ï¼Œå¹¶æä¾›äº†ä»¥ä¸‹åŸºç¡€å¯è§‚æµ‹å€¼ï¼Œç”¨æˆ·æ— éœ€ç‰¹æ®Šé…ç½®ï¼š

- metricï¼šæä¾›äº†è¾“å…¥ tokenã€è¾“å‡º tokenã€é¦–ä¸ª token çš„ rtï¼ˆæµå¼è¯·æ±‚ï¼‰ã€è¯·æ±‚æ€» rt ç­‰æŒ‡æ ‡ï¼Œæ”¯æŒåœ¨ç½‘å…³ã€è·¯ç”±ã€æœåŠ¡ã€æ¨¡å‹å››ä¸ªç»´åº¦ä¸Šè¿›è¡Œè§‚æµ‹
- logï¼šæä¾›äº† input_token, output_token, model, llm_service_duration, llm_first_token_duration ç­‰å­—æ®µ

ç”¨æˆ·è¿˜å¯ä»¥é€šè¿‡é…ç½®çš„æ–¹å¼å¯¹å¯è§‚æµ‹çš„å€¼è¿›è¡Œæ‰©å±•ï¼š

| åç§°             | æ•°æ®ç±»å‹  | å¡«å†™è¦æ±‚ | é»˜è®¤å€¼ | æè¿°                     |
|----------------|-------|------|-----|------------------------|
| `attributes` | []Attribute | éå¿…å¡«  | -   | ç”¨æˆ·å¸Œæœ›è®°å½•åœ¨log/spanä¸­çš„ä¿¡æ¯ |
| `disable_openai_usage` | bool | éå¿…å¡«  | false   | éopenaiå…¼å®¹åè®®æ—¶ï¼Œmodelã€tokençš„æ”¯æŒéæ ‡ï¼Œé…ç½®ä¸ºtrueæ—¶å¯ä»¥é¿å…æŠ¥é”™ |
| `value_length_limit` | int | éå¿…å¡«  | 4000   | è®°å½•çš„å•ä¸ªvalueçš„é•¿åº¦é™åˆ¶ |
| `enable_path_suffixes` | []string    | éå¿…å¡«   | []     | åªå¯¹è¿™äº›ç‰¹å®šè·¯å¾„åç¼€çš„è¯·æ±‚ç”Ÿæ•ˆï¼Œå¯ä»¥é…ç½®ä¸º "\*" ä»¥åŒ¹é…æ‰€æœ‰è·¯å¾„ï¼ˆé€šé…ç¬¦æ£€æŸ¥ä¼šä¼˜å…ˆè¿›è¡Œä»¥æé«˜æ€§èƒ½ï¼‰ã€‚å¦‚æœä¸ºç©ºæ•°ç»„ï¼Œåˆ™å¯¹æ‰€æœ‰è·¯å¾„ç”Ÿæ•ˆ |
| `enable_content_types` | []string    | éå¿…å¡«   | []     | åªå¯¹è¿™äº›å†…å®¹ç±»å‹çš„å“åº”è¿›è¡Œç¼“å†²å¤„ç†ã€‚å¦‚æœä¸ºç©ºæ•°ç»„ï¼Œåˆ™å¯¹æ‰€æœ‰å†…å®¹ç±»å‹ç”Ÿæ•ˆ                                                           |
| `session_id_header` | string | éå¿…å¡«  | -   | æŒ‡å®šè¯»å– session ID çš„ header åç§°ã€‚å¦‚æœä¸é…ç½®ï¼Œå°†æŒ‰ä»¥ä¸‹ä¼˜å…ˆçº§è‡ªåŠ¨æŸ¥æ‰¾ï¼š`x-openclaw-session-key`ã€`x-clawdbot-session-key`ã€`x-moltbot-session-key`ã€`x-agent-session`ã€‚session ID å¯ç”¨äºè¿½è¸ªå¤šè½® Agent å¯¹è¯ |

Attribute é…ç½®è¯´æ˜:

| åç§°                    | æ•°æ®ç±»å‹ | å¡«å†™è¦æ±‚ | é»˜è®¤å€¼ | æè¿°                                                                                                                                        |
| ----------------------- | -------- | -------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------------- |
| `key`                   | string   | å¿…å¡«     | -      | attribute åç§°                                                                                                                              |
| `value_source`          | string   | å¿…å¡«     | -      | attribute å–å€¼æ¥æºï¼Œå¯é€‰å€¼ä¸º `fixed_value`, `request_header`, `request_body`, `response_header`, `response_body`, `response_streaming_body` |
| `value`                 | string   | å¿…å¡«     | -      | attribute å–å€¼ key value/path                                                                                                               |
| `default_value`         | string   | éå¿…å¡«   | -      | attribute é»˜è®¤å€¼                                                                                                                            |
| `rule`                  | string   | éå¿…å¡«   | -      | ä»æµå¼å“åº”ä¸­æå– attribute çš„è§„åˆ™ï¼Œå¯é€‰å€¼ä¸º `first`, `replace`, `append`                                                                    |
| `apply_to_log`          | bool     | éå¿…å¡«   | false  | æ˜¯å¦å°†æå–çš„ä¿¡æ¯è®°å½•åœ¨æ—¥å¿—ä¸­                                                                                                                |
| `apply_to_span`         | bool     | éå¿…å¡«   | false  | æ˜¯å¦å°†æå–çš„ä¿¡æ¯è®°å½•åœ¨é“¾è·¯è¿½è¸ª span ä¸­                                                                                                      |
| `trace_span_key`        | string   | éå¿…å¡«   | -      | é“¾è·¯è¿½è¸ª attribute keyï¼Œé»˜è®¤ä¼šä½¿ç”¨`key`çš„è®¾ç½®                                                                                               |
| `as_separate_log_field` | bool     | éå¿…å¡«   | false  | è®°å½•æ—¥å¿—æ—¶æ˜¯å¦ä½œä¸ºå•ç‹¬çš„å­—æ®µï¼Œæ—¥å¿—å­—æ®µåä½¿ç”¨`key`çš„è®¾ç½®                                                                                     |

`value_source` çš„å„ç§å–å€¼å«ä¹‰å¦‚ä¸‹ï¼š

- `fixed_value`ï¼šå›ºå®šå€¼
- `request_header` ï¼š attribute å€¼é€šè¿‡ http è¯·æ±‚å¤´è·å–ï¼Œvalue é…ç½®ä¸º header key
- `request_body` ï¼šattribute å€¼é€šè¿‡è¯·æ±‚ body è·å–ï¼Œvalue é…ç½®æ ¼å¼ä¸º gjson çš„ jsonpath
- `response_header` ï¼šattribute å€¼é€šè¿‡ http å“åº”å¤´è·å–ï¼Œvalue é…ç½®ä¸º header key
- `response_body` ï¼šattribute å€¼é€šè¿‡å“åº” body è·å–ï¼Œvalue é…ç½®æ ¼å¼ä¸º gjson çš„ jsonpath
- `response_streaming_body` ï¼šattribute å€¼é€šè¿‡æµå¼å“åº” body è·å–ï¼Œvalue é…ç½®æ ¼å¼ä¸º gjson çš„ jsonpath

å½“ `value_source` ä¸º `response_streaming_body` æ—¶ï¼Œåº”å½“é…ç½® `rule`ï¼Œç”¨äºæŒ‡å®šå¦‚ä½•ä»æµå¼ body ä¸­è·å–æŒ‡å®šå€¼ï¼Œå–å€¼å«ä¹‰å¦‚ä¸‹ï¼š

- `first`ï¼šå¤šä¸ª chunk ä¸­å–ç¬¬ä¸€ä¸ªæœ‰æ•ˆ chunk çš„å€¼
- `replace`ï¼šå¤šä¸ª chunk ä¸­å–æœ€åä¸€ä¸ªæœ‰æ•ˆ chunk çš„å€¼
- `append`ï¼šæ‹¼æ¥å¤šä¸ªæœ‰æ•ˆ chunk ä¸­çš„å€¼ï¼Œå¯ç”¨äºè·å–å›ç­”å†…å®¹

### å†…ç½®å±æ€§ (Built-in Attributes)

æ’ä»¶æä¾›äº†ä¸€äº›å†…ç½®å±æ€§é”®ï¼ˆkeyï¼‰ï¼Œå¯ä»¥ç›´æ¥ä½¿ç”¨è€Œæ— éœ€é…ç½® `value_source` å’Œ `value`ã€‚è¿™äº›å†…ç½®å±æ€§ä¼šè‡ªåŠ¨ä»è¯·æ±‚/å“åº”ä¸­æå–ç›¸åº”çš„å€¼ï¼š

| å†…ç½®å±æ€§é”® | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|---------|------|---------|
| `question` | ç”¨æˆ·æé—®å†…å®¹ | æ”¯æŒ OpenAI/Claude æ¶ˆæ¯æ ¼å¼ |
| `answer` | AI å›ç­”å†…å®¹ | æ”¯æŒ OpenAI/Claude æ¶ˆæ¯æ ¼å¼ï¼Œæµå¼å’Œéæµå¼ |
| `tool_calls` | å·¥å…·è°ƒç”¨ä¿¡æ¯ | OpenAI/Claude å·¥å…·è°ƒç”¨ |
| `reasoning` | æ¨ç†è¿‡ç¨‹ | OpenAI o1 ç­‰æ¨ç†æ¨¡å‹ |
| `reasoning_tokens` | æ¨ç† token æ•°ï¼ˆå¦‚ o1 æ¨¡å‹ï¼‰ | OpenAI Chat Completionsï¼Œä» `output_token_details.reasoning_tokens` æå– |
| `cached_tokens` | ç¼“å­˜å‘½ä¸­çš„ token æ•° | OpenAI Chat Completionsï¼Œä» `input_token_details.cached_tokens` æå– |
| `input_token_details` | è¾“å…¥ token è¯¦ç»†ä¿¡æ¯ï¼ˆå®Œæ•´å¯¹è±¡ï¼‰ | OpenAI/Gemini/Anthropicï¼ŒåŒ…å«ç¼“å­˜ã€å·¥å…·ä½¿ç”¨ç­‰è¯¦æƒ… |
| `output_token_details` | è¾“å‡º token è¯¦ç»†ä¿¡æ¯ï¼ˆå®Œæ•´å¯¹è±¡ï¼‰ | OpenAI/Gemini/Anthropicï¼ŒåŒ…å«æ¨ç† tokenã€ç”Ÿæˆå›¾ç‰‡æ•°ç­‰è¯¦æƒ… |

ä½¿ç”¨å†…ç½®å±æ€§æ—¶ï¼Œåªéœ€è®¾ç½® `key`ã€`apply_to_log` ç­‰å‚æ•°ï¼Œæ— éœ€è®¾ç½® `value_source` å’Œ `value`ã€‚

**æ³¨æ„**ï¼š
- `reasoning_tokens` å’Œ `cached_tokens` æ˜¯ä» token details ä¸­æå–çš„ä¾¿æ·å­—æ®µï¼Œé€‚ç”¨äº OpenAI Chat Completions API
- `input_token_details` å’Œ `output_token_details` ä¼šä»¥ JSON å­—ç¬¦ä¸²å½¢å¼è®°å½•å®Œæ•´çš„ token è¯¦æƒ…å¯¹è±¡

## é…ç½®ç¤ºä¾‹

å¦‚æœå¸Œæœ›åœ¨ç½‘å…³è®¿é—®æ—¥å¿—ä¸­è®°å½• ai-statistic ç›¸å…³çš„ç»Ÿè®¡å€¼ï¼Œéœ€è¦ä¿®æ”¹ log_formatï¼Œåœ¨åŸ log_format åŸºç¡€ä¸Šæ·»åŠ ä¸€ä¸ªæ–°å­—æ®µï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š

```yaml
'{"ai_log":"%FILTER_STATE(wasm.ai_log:PLAIN)%"}'
```

å¦‚æœå­—æ®µè®¾ç½®äº† `as_separate_log_field`ï¼Œä¾‹å¦‚ï¼š

```yaml
attributes:
  - key: consumer
    value_source: request_header
    value: x-mse-consumer
    apply_to_log: true
    as_separate_log_field: true
```

é‚£ä¹ˆè¦åœ¨æ—¥å¿—ä¸­æ‰“å°ï¼Œéœ€è¦é¢å¤–è®¾ç½® log_formatï¼š

```
'{"consumer":"%FILTER_STATE(wasm.consumer:PLAIN)%"}'
```

### ç©ºé…ç½®

#### ç›‘æ§

```
# counter ç±»å‹ï¼Œè¾“å…¥ token æ•°é‡çš„ç´¯åŠ å€¼
route_upstream_model_consumer_metric_input_token{ai_route="ai-route-aliyun.internal",ai_cluster="outbound|443||llm-aliyun.internal.dns",ai_model="qwen-turbo",ai_consumer="none"} 24

# counter ç±»å‹ï¼Œè¾“å‡º token æ•°é‡çš„ç´¯åŠ å€¼
route_upstream_model_consumer_metric_output_token{ai_route="ai-route-aliyun.internal",ai_cluster="outbound|443||llm-aliyun.internal.dns",ai_model="qwen-turbo",ai_consumer="none"} 507

# counter ç±»å‹ï¼Œæµå¼è¯·æ±‚å’Œéæµå¼è¯·æ±‚æ¶ˆè€—æ€»æ—¶é—´çš„ç´¯åŠ å€¼
route_upstream_model_consumer_metric_llm_service_duration{ai_route="ai-route-aliyun.internal",ai_cluster="outbound|443||llm-aliyun.internal.dns",ai_model="qwen-turbo",ai_consumer="none"} 6470

# counter ç±»å‹ï¼Œæµå¼è¯·æ±‚å’Œéæµå¼è¯·æ±‚æ¬¡æ•°çš„ç´¯åŠ å€¼
route_upstream_model_consumer_metric_llm_duration_count{ai_route="ai-route-aliyun.internal",ai_cluster="outbound|443||llm-aliyun.internal.dns",ai_model="qwen-turbo",ai_consumer="none"} 2

# counter ç±»å‹ï¼Œæµå¼è¯·æ±‚é¦–ä¸ª token å»¶æ—¶çš„ç´¯åŠ å€¼
route_upstream_model_consumer_metric_llm_first_token_duration{ai_route="ai-route-aliyun.internal",ai_cluster="outbound|443||llm-aliyun.internal.dns",ai_model="qwen-turbo",ai_consumer="none"} 340

# counter ç±»å‹ï¼Œæµå¼è¯·æ±‚æ¬¡æ•°çš„ç´¯åŠ å€¼
route_upstream_model_consumer_metric_llm_stream_duration_count{ai_route="ai-route-aliyun.internal",ai_cluster="outbound|443||llm-aliyun.internal.dns",ai_model="qwen-turbo",ai_consumer="none"} 1
```

ä»¥ä¸‹æ˜¯ä½¿ç”¨æŒ‡æ ‡çš„å‡ ä¸ªç¤ºä¾‹ï¼š

æµå¼è¯·æ±‚é¦–ä¸ª token çš„å¹³å‡å»¶æ—¶ï¼š

```
irate(route_upstream_model_consumer_metric_llm_first_token_duration[2m])
/
irate(route_upstream_model_consumer_metric_llm_stream_duration_count[2m])
```

æµå¼è¯·æ±‚å’Œéæµå¼è¯·æ±‚å¹³å‡æ¶ˆè€—çš„æ€»æ—¶é•¿ï¼š

```
irate(route_upstream_model_consumer_metric_llm_service_duration[2m])
/
irate(route_upstream_model_consumer_metric_llm_duration_count[2m])
```

#### æ—¥å¿—

```json
{
  "ai_log": "{\"model\":\"qwen-turbo\",\"input_token\":\"10\",\"output_token\":\"69\",\"llm_first_token_duration\":\"309\",\"llm_service_duration\":\"1955\"}"
}
```

å¦‚æœè¯·æ±‚ä¸­æºå¸¦äº† session ID headerï¼Œæ—¥å¿—ä¸­ä¼šè‡ªåŠ¨æ·»åŠ  `session_id` å­—æ®µï¼š

```json
{
  "ai_log": "{\"session_id\":\"sess_abc123\",\"model\":\"qwen-turbo\",\"input_token\":\"10\",\"output_token\":\"69\",\"llm_first_token_duration\":\"309\",\"llm_service_duration\":\"1955\"}"
}
```

#### é“¾è·¯è¿½è¸ª

é…ç½®ä¸ºç©ºæ—¶ï¼Œä¸ä¼šåœ¨ span ä¸­æ·»åŠ é¢å¤–çš„ attribute

### ä»é openai åè®®æå– token ä½¿ç”¨ä¿¡æ¯

åœ¨ ai-proxy ä¸­è®¾ç½®åè®®ä¸º original æ—¶ï¼Œä»¥ç™¾ç‚¼ä¸ºä¾‹ï¼Œå¯ä½œå¦‚ä¸‹é…ç½®æŒ‡å®šå¦‚ä½•æå– model, input_token, output_token

```yaml
attributes:
  - key: model
    value_source: response_body
    value: usage.models.0.model_id
    apply_to_log: true
    apply_to_span: false
  - key: input_token
    value_source: response_body
    value: usage.models.0.input_tokens
    apply_to_log: true
    apply_to_span: false
  - key: output_token
    value_source: response_body
    value: usage.models.0.output_tokens
    apply_to_log: true
    apply_to_span: false
```

#### ç›‘æ§

```
route_upstream_model_consumer_metric_input_token{ai_route="bailian",ai_cluster="qwen",ai_model="qwen-max"} 343
route_upstream_model_consumer_metric_output_token{ai_route="bailian",ai_cluster="qwen",ai_model="qwen-max"} 153
route_upstream_model_consumer_metric_llm_service_duration{ai_route="bailian",ai_cluster="qwen",ai_model="qwen-max"} 3725
route_upstream_model_consumer_metric_llm_duration_count{ai_route="bailian",ai_cluster="qwen",ai_model="qwen-max"} 1
```

#### æ—¥å¿—

æ­¤é…ç½®ä¸‹æ—¥å¿—æ•ˆæœå¦‚ä¸‹ï¼š

```json
{
  "ai_log": "{\"model\":\"qwen-max\",\"input_token\":\"343\",\"output_token\":\"153\",\"llm_service_duration\":\"19110\"}"
}
```

#### é“¾è·¯è¿½è¸ª

é“¾è·¯è¿½è¸ªçš„ span ä¸­å¯ä»¥çœ‹åˆ° model, input_token, output_token ä¸‰ä¸ªé¢å¤–çš„ attribute

### é…åˆè®¤è¯é‰´æƒè®°å½• consumer

ä¸¾ä¾‹å¦‚ä¸‹ï¼š

```yaml
attributes:
  - key: consumer # é…åˆè®¤è¯é‰´æƒè®°å½•consumer
    value_source: request_header
    value: x-mse-consumer
    apply_to_log: true
```

### è®°å½•é—®é¢˜ä¸å›ç­”

#### ä»…è®°å½•å½“å‰è½®æ¬¡çš„é—®é¢˜ä¸å›ç­”

```yaml
attributes:
  - key: question # è®°å½•å½“å‰è½®æ¬¡çš„é—®é¢˜ï¼ˆæœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ï¼‰
    value_source: request_body
    value: messages.@reverse.0.content
    apply_to_log: true
  - key: answer # åœ¨æµå¼å“åº”ä¸­æå–å¤§æ¨¡å‹çš„å›ç­”
    value_source: response_streaming_body
    value: choices.0.delta.content
    rule: append
    apply_to_log: true
  - key: answer # åœ¨éæµå¼å“åº”ä¸­æå–å¤§æ¨¡å‹çš„å›ç­”
    value_source: response_body
    value: choices.0.message.content
    apply_to_log: true
```

#### è®°å½•å®Œæ•´çš„å¤šè½®å¯¹è¯å†å²ï¼ˆæ¨èé…ç½®ï¼‰

å¯¹äºå¤šè½® Agent å¯¹è¯åœºæ™¯ï¼Œä½¿ç”¨å†…ç½®å±æ€§å¯ä»¥å¤§å¹…ç®€åŒ–é…ç½®ï¼š

```yaml
session_id_header: "x-session-id"  # å¯é€‰ï¼ŒæŒ‡å®š session ID header
attributes:
  - key: messages     # å®Œæ•´å¯¹è¯å†å²
    value_source: request_body
    value: messages
    apply_to_log: true
  - key: question     # å†…ç½®å±æ€§ï¼Œè‡ªåŠ¨æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
    apply_to_log: true
  - key: answer       # å†…ç½®å±æ€§ï¼Œè‡ªåŠ¨æå–å›ç­”
    apply_to_log: true
  - key: reasoning    # å†…ç½®å±æ€§ï¼Œè‡ªåŠ¨æå–æ€è€ƒè¿‡ç¨‹
    apply_to_log: true
  - key: tool_calls   # å†…ç½®å±æ€§ï¼Œè‡ªåŠ¨æå–å·¥å…·è°ƒç”¨
    apply_to_log: true
```

**å†…ç½®å±æ€§è¯´æ˜ï¼š**

æ’ä»¶æä¾›ä»¥ä¸‹å†…ç½®å±æ€§ keyï¼Œæ— éœ€é…ç½® `value_source` å’Œ `value` å­—æ®µå³å¯è‡ªåŠ¨æå–ï¼š

| å†…ç½® Key | è¯´æ˜ | é»˜è®¤ value_source |
|---------|------|-------------------|
| `question` | è‡ªåŠ¨æå–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ | `request_body` |
| `answer` | è‡ªåŠ¨æå–å›ç­”å†…å®¹ï¼ˆæ”¯æŒ OpenAI/Claude åè®®ï¼‰ | `response_streaming_body` / `response_body` |
| `tool_calls` | è‡ªåŠ¨æå–å¹¶æ‹¼æ¥å·¥å…·è°ƒç”¨ï¼ˆæµå¼åœºæ™¯è‡ªåŠ¨æŒ‰ index æ‹¼æ¥ argumentsï¼‰ | `response_streaming_body` / `response_body` |
| `reasoning` | è‡ªåŠ¨æå–æ€è€ƒè¿‡ç¨‹ï¼ˆreasoning_contentï¼Œå¦‚ DeepSeek-R1ï¼‰ | `response_streaming_body` / `response_body` |

> **æ³¨æ„**ï¼šå¦‚æœé…ç½®äº† `value_source` å’Œ `value`ï¼Œå°†ä¼˜å…ˆä½¿ç”¨é…ç½®çš„å€¼ï¼Œä»¥ä¿æŒå‘åå…¼å®¹ã€‚

æ—¥å¿—è¾“å‡ºç¤ºä¾‹ï¼š

```json
{
  "ai_log": "{\"session_id\":\"sess_abc123\",\"messages\":[{\"role\":\"user\",\"content\":\"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}],\"question\":\"åŒ—äº¬å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\",\"reasoning\":\"ç”¨æˆ·æƒ³çŸ¥é“åŒ—äº¬çš„å¤©æ°”ï¼Œæˆ‘éœ€è¦è°ƒç”¨å¤©æ°”æŸ¥è¯¢å·¥å…·ã€‚\",\"tool_calls\":[{\"index\":0,\"id\":\"call_abc123\",\"type\":\"function\",\"function\":{\"name\":\"get_weather\",\"arguments\":\"{\\\"location\\\":\\\"Beijing\\\"}\"}}],\"model\":\"deepseek-reasoner\"}"
}
```

**æµå¼å“åº”ä¸­çš„ tool_calls å¤„ç†ï¼š**

æ’ä»¶ä¼šè‡ªåŠ¨æŒ‰ `index` å­—æ®µè¯†åˆ«æ¯ä¸ªç‹¬ç«‹çš„å·¥å…·è°ƒç”¨ï¼Œæ‹¼æ¥åˆ†ç‰‡è¿”å›çš„ `arguments` å­—ç¬¦ä¸²ï¼Œæœ€ç»ˆè¾“å‡ºå®Œæ•´çš„å·¥å…·è°ƒç”¨åˆ—è¡¨ã€‚

### è®°å½• Token è¯¦æƒ…

ä½¿ç”¨å†…ç½®å±æ€§è®°å½• OpenAI Chat Completions çš„ token è¯¦ç»†ä¿¡æ¯ï¼š

```yaml
attributes:
  # ä½¿ç”¨ä¾¿æ·çš„å†…ç½®å±æ€§æå–ç‰¹å®šå­—æ®µ
  - key: reasoning_tokens  # æ¨ç†tokenæ•°ï¼ˆo1ç­‰æ¨ç†æ¨¡å‹ï¼‰
    apply_to_log: true
  - key: cached_tokens  # ç¼“å­˜å‘½ä¸­çš„tokenæ•°
    apply_to_log: true
  # è®°å½•å®Œæ•´çš„tokenè¯¦æƒ…å¯¹è±¡
  - key: input_token_details
    apply_to_log: true
  - key: output_token_details
    apply_to_log: true
```

#### æ—¥å¿—ç¤ºä¾‹

å¯¹äºä½¿ç”¨äº† prompt caching å’Œæ¨ç†æ¨¡å‹çš„è¯·æ±‚ï¼Œæ—¥å¿—å¯èƒ½å¦‚ä¸‹ï¼š

```json
{
  "ai_log": "{\"model\":\"gpt-4o\",\"input_token\":\"100\",\"output_token\":\"50\",\"reasoning_tokens\":\"25\",\"cached_tokens\":\"80\",\"input_token_details\":\"{\\\"cached_tokens\\\":80}\",\"output_token_details\":\"{\\\"reasoning_tokens\\\":25}\",\"llm_service_duration\":\"2000\"}"
}
```

å…¶ä¸­ï¼š
- `reasoning_tokens`: 25 - æ¨ç†è¿‡ç¨‹äº§ç”Ÿçš„ token æ•°
- `cached_tokens`: 80 - ä»ç¼“å­˜ä¸­è¯»å–çš„ token æ•°
- `input_token_details`: å®Œæ•´çš„è¾“å…¥ token è¯¦æƒ…ï¼ˆJSON æ ¼å¼ï¼‰
- `output_token_details`: å®Œæ•´çš„è¾“å‡º token è¯¦æƒ…ï¼ˆJSON æ ¼å¼ï¼‰

è¿™äº›è¯¦æƒ…å¯¹äºï¼š
1. **æˆæœ¬ä¼˜åŒ–**ï¼šäº†è§£ç¼“å­˜å‘½ä¸­ç‡ï¼Œä¼˜åŒ– prompt caching ç­–ç•¥
2. **æ€§èƒ½åˆ†æ**ï¼šåˆ†ææ¨ç† token å æ¯”ï¼Œè¯„ä¼°æ¨ç†æ¨¡å‹çš„å®é™…å¼€é”€
3. **ä½¿ç”¨ç»Ÿè®¡**ï¼šç»†ç²’åº¦ç»Ÿè®¡å„ç±» token çš„ä½¿ç”¨æƒ…å†µ

## æµå¼å“åº”è§‚æµ‹èƒ½åŠ›

æµå¼ï¼ˆStreamingï¼‰å“åº”æ˜¯ AI å¯¹è¯çš„å¸¸è§åœºæ™¯ï¼Œæ’ä»¶æä¾›äº†å®Œå–„çš„æµå¼è§‚æµ‹æ”¯æŒï¼Œèƒ½å¤Ÿæ­£ç¡®æ‹¼æ¥å’Œæå–æµå¼å“åº”ä¸­çš„å…³é”®ä¿¡æ¯ã€‚

### æµå¼å“åº”çš„æŒ‘æˆ˜

æµå¼å“åº”å°†å®Œæ•´å†…å®¹æ‹†åˆ†ä¸ºå¤šä¸ª SSE chunk é€æ­¥è¿”å›ï¼Œä¾‹å¦‚ï¼š

```
data: {"choices":[{"delta":{"content":"Hello"}}]}
data: {"choices":[{"delta":{"content":" ğŸ‘‹"}}]}
data: {"choices":[{"delta":{"content":"!"}}]}
data: [DONE]
```

è¦è·å–å®Œæ•´çš„å›ç­”å†…å®¹ï¼Œéœ€è¦å°†å„ä¸ª chunk ä¸­çš„ `delta.content` æ‹¼æ¥èµ·æ¥ã€‚

### è‡ªåŠ¨æ‹¼æ¥æœºåˆ¶

æ’ä»¶é’ˆå¯¹ä¸åŒç±»å‹çš„å†…å®¹æä¾›äº†è‡ªåŠ¨æ‹¼æ¥èƒ½åŠ›ï¼š

| å†…å®¹ç±»å‹ | æ‹¼æ¥æ–¹å¼ | è¯´æ˜ |
|---------|---------|------|
| `answer` | æ–‡æœ¬è¿½åŠ ï¼ˆappendï¼‰ | å°†å„ chunk çš„ `delta.content` æŒ‰é¡ºåºæ‹¼æ¥æˆå®Œæ•´å›ç­” |
| `reasoning` | æ–‡æœ¬è¿½åŠ ï¼ˆappendï¼‰ | å°†å„ chunk çš„ `delta.reasoning_content` æŒ‰é¡ºåºæ‹¼æ¥ |
| `tool_calls` | æŒ‰ index ç»„è£… | è¯†åˆ«æ¯ä¸ªå·¥å…·è°ƒç”¨çš„ `index`ï¼Œåˆ†åˆ«æ‹¼æ¥å„è‡ªçš„ `arguments` |

#### answer å’Œ reasoning æ‹¼æ¥ç¤ºä¾‹

æµå¼å“åº”ï¼š
```
data: {"choices":[{"delta":{"content":"ä½ å¥½"}}]}
data: {"choices":[{"delta":{"content":"ï¼Œæˆ‘æ˜¯"}}]}
data: {"choices":[{"delta":{"content":"AIåŠ©æ‰‹"}}]}
```

æœ€ç»ˆæå–çš„ `answer`ï¼š`"ä½ å¥½ï¼Œæˆ‘æ˜¯AIåŠ©æ‰‹"`

#### tool_calls æ‹¼æ¥ç¤ºä¾‹

æµå¼å“åº”ï¼ˆå¤šä¸ªå¹¶è¡Œå·¥å…·è°ƒç”¨ï¼‰ï¼š
```
data: {"choices":[{"delta":{"tool_calls":[{"index":0,"id":"call_001","function":{"name":"get_weather"}}]}}]}
data: {"choices":[{"delta":{"tool_calls":[{"index":1,"id":"call_002","function":{"name":"get_time"}}]}}]}
data: {"choices":[{"delta":{"tool_calls":[{"index":0,"function":{"arguments":"{\"city\":"}}]}}]}
data: {"choices":[{"delta":{"tool_calls":[{"index":0,"function":{"arguments":"\"Beijing\"}"}}]}}]}
data: {"choices":[{"delta":{"tool_calls":[{"index":1,"function":{"arguments":"{\"city\":\"Shanghai\"}"}}]}}]}
```

æœ€ç»ˆæå–çš„ `tool_calls`ï¼š
```json
[
  {"index":0,"id":"call_001","function":{"name":"get_weather","arguments":"{\"city\":\"Beijing\"}"}},
  {"index":1,"id":"call_002","function":{"name":"get_time","arguments":"{\"city\":\"Shanghai\"}"}}
]
```

### ä½¿ç”¨é»˜è®¤é…ç½®å¿«é€Ÿå¯ç”¨

é€šè¿‡ `use_default_attributes: true` å¯ä»¥ä¸€é”®å¯ç”¨å®Œæ•´çš„æµå¼è§‚æµ‹èƒ½åŠ›ï¼š

```yaml
use_default_attributes: true
```

æ­¤é…ç½®ä¼šè‡ªåŠ¨è®°å½•ä»¥ä¸‹å­—æ®µï¼š

| å­—æ®µ | è¯´æ˜ |
|------|------|
| `messages` | å®Œæ•´å¯¹è¯å†å² |
| `question` | æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯ |
| `answer` | AI å›ç­”ï¼ˆè‡ªåŠ¨æ‹¼æ¥æµå¼ chunkï¼‰ |
| `reasoning` | æ¨ç†è¿‡ç¨‹ï¼ˆè‡ªåŠ¨æ‹¼æ¥æµå¼ chunkï¼‰ |
| `tool_calls` | å·¥å…·è°ƒç”¨ï¼ˆè‡ªåŠ¨æŒ‰ index ç»„è£…ï¼‰ |
| `reasoning_tokens` | æ¨ç† token æ•° |
| `cached_tokens` | ç¼“å­˜å‘½ä¸­ token æ•° |
| `input_token_details` | è¾“å…¥ token è¯¦æƒ… |
| `output_token_details` | è¾“å‡º token è¯¦æƒ… |

### æµå¼æ—¥å¿—ç¤ºä¾‹

å¯ç”¨é»˜è®¤é…ç½®åï¼Œä¸€ä¸ªæµå¼è¯·æ±‚çš„æ—¥å¿—è¾“å‡ºç¤ºä¾‹ï¼š

```json
{
  "answer": "2 plus 2 equals 4.",
  "question": "What is 2+2?",
  "response_type": "stream",
  "tool_calls": null,
  "reasoning": null,
  "model": "glm-4-flash",
  "input_token": 10,
  "output_token": 8,
  "llm_first_token_duration": 425,
  "llm_service_duration": 985,
  "chat_id": "chat_abc123"
}
```

åŒ…å«å·¥å…·è°ƒç”¨çš„æµå¼æ—¥å¿—ç¤ºä¾‹ï¼š

```json
{
  "answer": null,
  "question": "What's the weather in Beijing?",
  "response_type": "stream",
  "tool_calls": [
    {
      "id": "call_abc123",
      "type": "function",
      "function": {
        "name": "get_weather",
        "arguments": "{\"location\": \"Beijing\"}"
      }
    }
  ],
  "model": "glm-4-flash",
  "input_token": 50,
  "output_token": 15,
  "llm_first_token_duration": 300,
  "llm_service_duration": 500
}
```

### æµå¼ç‰¹æœ‰æŒ‡æ ‡

æµå¼å“åº”ä¼šé¢å¤–è®°å½•ä»¥ä¸‹æŒ‡æ ‡ï¼š

- `llm_first_token_duration`ï¼šä»è¯·æ±‚å‘å‡ºåˆ°æ”¶åˆ°é¦–ä¸ª token çš„æ—¶é—´ï¼ˆé¦–å­—å»¶è¿Ÿï¼‰
- `llm_stream_duration_count`ï¼šæµå¼è¯·æ±‚æ¬¡æ•°

å¯ç”¨äºç›‘æ§æµå¼å“åº”çš„ç”¨æˆ·ä½“éªŒï¼š

```promql
# å¹³å‡é¦–å­—å»¶è¿Ÿ
irate(route_upstream_model_consumer_metric_llm_first_token_duration[5m])
/
irate(route_upstream_model_consumer_metric_llm_stream_duration_count[5m])
```

## è°ƒè¯•

### éªŒè¯ ai_log å†…å®¹

åœ¨æµ‹è¯•æˆ–è°ƒè¯•è¿‡ç¨‹ä¸­ï¼Œå¯ä»¥é€šè¿‡å¼€å¯ Higress çš„ debug æ—¥å¿—æ¥éªŒè¯ ai_log çš„å†…å®¹ï¼š

```bash
# æ—¥å¿—æ ¼å¼ç¤ºä¾‹
2026/01/31 23:29:30 proxy_debug_log: [ai-statistics] [nil] [test-request-id] [ai_log] attributes to be written: {"question":"What is 2+2?","answer":"4","reasoning":"...","tool_calls":[...],"session_id":"sess_123","model":"gpt-4","input_token":20,"output_token":10}
```

é€šè¿‡è¿™ä¸ªdebugæ—¥å¿—å¯ä»¥éªŒè¯ï¼š
- question/answer/reasoning æ˜¯å¦æ­£ç¡®æå–
- tool_calls æ˜¯å¦æ­£ç¡®æ‹¼æ¥ï¼ˆç‰¹åˆ«æ˜¯æµå¼åœºæ™¯ä¸‹çš„argumentsï¼‰
- session_id æ˜¯å¦æ­£ç¡®è¯†åˆ«
- å„ä¸ªå­—æ®µæ˜¯å¦ç¬¦åˆé¢„æœŸ

## è¿›é˜¶

é…åˆé˜¿é‡Œäº‘ SLS æ•°æ®åŠ å·¥ï¼Œå¯ä»¥å°† ai ç›¸å…³çš„å­—æ®µè¿›è¡Œæå–åŠ å·¥ï¼Œä¾‹å¦‚åŸå§‹æ—¥å¿—ä¸ºï¼š

````
ai_log:{"question":"ç”¨pythonè®¡ç®—2çš„3æ¬¡æ–¹","answer":"ä½ å¯ä»¥ä½¿ç”¨ Python çš„ä¹˜æ–¹è¿ç®—ç¬¦ `**` æ¥è®¡ç®—ä¸€ä¸ªæ•°çš„æ¬¡æ–¹ã€‚è®¡ç®—2çš„3æ¬¡æ–¹ï¼Œå³2ä¹˜ä»¥è‡ªå·±2æ¬¡ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹ä»£ç è¡¨ç¤ºï¼š\n\n```python\nresult = 2 ** 3\nprint(result)\n```\n\nè¿è¡Œè¿™æ®µä»£ç ï¼Œä½ ä¼šå¾—åˆ°è¾“å‡ºç»“æœä¸º8ï¼Œå› ä¸º2ä¹˜ä»¥è‡ªå·±ä¸¤æ¬¡ç­‰äº8ã€‚","model":"qwen-max","input_token":"16","output_token":"76","llm_service_duration":"5913"}
````

ä½¿ç”¨å¦‚ä¸‹æ•°æ®åŠ å·¥è„šæœ¬ï¼Œå¯ä»¥æå–å‡º question å’Œ answerï¼š

```
e_regex("ai_log", grok("%{EXTRACTJSON}"))
e_set("question", json_select(v("json"), "question", default="-"))
e_set("answer", json_select(v("json"), "answer", default="-"))
```

æå–åï¼ŒSLS ä¸­ä¼šæ·»åŠ  question å’Œ answer ä¸¤ä¸ªå­—æ®µï¼Œç¤ºä¾‹å¦‚ä¸‹ï¼š

````
ai_log:{"question":"ç”¨pythonè®¡ç®—2çš„3æ¬¡æ–¹","answer":"ä½ å¯ä»¥ä½¿ç”¨ Python çš„ä¹˜æ–¹è¿ç®—ç¬¦ `**` æ¥è®¡ç®—ä¸€ä¸ªæ•°çš„æ¬¡æ–¹ã€‚è®¡ç®—2çš„3æ¬¡æ–¹ï¼Œå³2ä¹˜ä»¥è‡ªå·±2æ¬¡ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹ä»£ç è¡¨ç¤ºï¼š\n\n```python\nresult = 2 ** 3\nprint(result)\n```\n\nè¿è¡Œè¿™æ®µä»£ç ï¼Œä½ ä¼šå¾—åˆ°è¾“å‡ºç»“æœä¸º8ï¼Œå› ä¸º2ä¹˜ä»¥è‡ªå·±ä¸¤æ¬¡ç­‰äº8ã€‚","model":"qwen-max","input_token":"16","output_token":"76","llm_service_duration":"5913"}

question:ç”¨pythonè®¡ç®—2çš„3æ¬¡æ–¹

answer:ä½ å¯ä»¥ä½¿ç”¨ Python çš„ä¹˜æ–¹è¿ç®—ç¬¦ `**` æ¥è®¡ç®—ä¸€ä¸ªæ•°çš„æ¬¡æ–¹ã€‚è®¡ç®—2çš„3æ¬¡æ–¹ï¼Œå³2ä¹˜ä»¥è‡ªå·±2æ¬¡ï¼Œå¯ä»¥ç”¨ä»¥ä¸‹ä»£ç è¡¨ç¤ºï¼š

result = 2 ** 3
print(result)

è¿è¡Œè¿™æ®µä»£ç ï¼Œä½ ä¼šå¾—åˆ°è¾“å‡ºç»“æœä¸º8ï¼Œå› ä¸º2ä¹˜ä»¥è‡ªå·±ä¸¤æ¬¡ç­‰äº8ã€‚

````

### è·¯å¾„å’Œå†…å®¹ç±»å‹è¿‡æ»¤é…ç½®ç¤ºä¾‹

#### åªå¤„ç†ç‰¹å®š AI è·¯å¾„

```yaml
enable_path_suffixes:
  - "/v1/chat/completions"
  - "/v1/embeddings"
  - "/generateContent"
```

#### åªå¤„ç†ç‰¹å®šå†…å®¹ç±»å‹

```yaml
enable_content_types:
  - "text/event-stream"
  - "application/json"
```

#### å¤„ç†æ‰€æœ‰è·¯å¾„ï¼ˆé€šé…ç¬¦ï¼‰

```yaml
enable_path_suffixes:
  - "*"
```

#### å¤„ç†æ‰€æœ‰å†…å®¹ç±»å‹ï¼ˆç©ºæ•°ç»„ï¼‰

```yaml
enable_content_types: []
```

#### å®Œæ•´é…ç½®ç¤ºä¾‹

```yaml
enable_path_suffixes:
  - "/v1/chat/completions"
  - "/v1/embeddings"
  - "/generateContent"
enable_content_types:
  - "text/event-stream"
  - "application/json"
attributes:
  - key: model
    value_source: request_body
    value: model
    apply_to_log: true
  - key: consumer
    value_source: request_header
    value: x-mse-consumer
    apply_to_log: true
```
