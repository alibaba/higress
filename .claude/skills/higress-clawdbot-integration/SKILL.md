# Higress Clawdbot Integration SKILL

Deploy and configure Higress AI Gateway for Clawdbot integration.

## Description

This skill helps users deploy Higress AI Gateway and integrate it with Clawdbot. It provides:

1. **One-click deployment**: Download and run the AI Gateway setup script
2. **Model provider configuration**: Configure LLM providers via CLI parameters
3. **Auto-routing setup**: Enable intelligent model routing based on message content
4. **Session monitoring**: Track token usage and conversation history

## When to Use

Use this skill when:
- User wants to deploy Higress AI Gateway
- User wants to configure Clawdbot to use Higress as a model provider
- User mentions "higress", "ai gateway", "model gateway", "ç»Ÿä¸€ç½‘å…³"
- User wants to set up model routing or auto-routing

## Prerequisites

- Docker installed and running
- Internet access to download the setup script
- LLM provider API keys (at least one)

## Workflow

### Step 1: Download Setup Script

Download the official get-ai-gateway.sh script:

```bash
curl -fsSL https://raw.githubusercontent.com/higress-group/higress-standalone/main/all-in-one/get-ai-gateway.sh -o get-ai-gateway.sh
chmod +x get-ai-gateway.sh
```

### Step 2: Gather Configuration

Ask the user for:
1. **LLM Provider API Keys**: At least one provider is required
   - Dashscope (Qwen): `--dashscope-key`
   - DeepSeek: `--deepseek-key`
   - OpenAI: `--openai-key`
   - OpenRouter: `--openrouter-key`
   - Claude: `--claude-key`
   - And more...

2. **Port Configuration** (optional):
   - HTTP port: `--http-port` (default: 8080)
   - HTTPS port: `--https-port` (default: 8443)
   - Console port: `--console-port` (default: 8001)

3. **Auto-routing** (optional):
   - Enable: `--auto-routing`
   - Default model: `--auto-routing-default-model`

### Step 3: Run Setup Script

Run the script in non-interactive mode with the gathered parameters:

```bash
./get-ai-gateway.sh start --non-interactive \
  --dashscope-key sk-xxx \
  --openai-key sk-xxx \
  --auto-routing \
  --auto-routing-default-model qwen-turbo
```

### Step 4: Verify Deployment

After the script completes:

1. Check container is running:
   ```bash
   docker ps --filter "name=higress-ai-gateway"
   ```

2. Test the gateway endpoint:
   ```bash
   curl http://localhost:8080/v1/models
   ```

3. Access the console (optional):
   ```
   http://localhost:8001
   ```

### Step 5: Configure Clawdbot (if applicable)

If the user wants to use Higress with Clawdbot:

```bash
clawdbot models auth login --provider higress
```

This will configure Clawdbot to use Higress AI Gateway as a model provider.

## CLI Parameters Reference

### Basic Options
| Parameter | Description | Default |
|-----------|-------------|---------|
| `--non-interactive` | Run without prompts | - |
| `--http-port` | Gateway HTTP port | 8080 |
| `--https-port` | Gateway HTTPS port | 8443 |
| `--console-port` | Console port | 8001 |
| `--container-name` | Container name | higress-ai-gateway |
| `--data-folder` | Data folder path | ./higress |

### Auto-Routing Options
| Parameter | Description |
|-----------|-------------|
| `--auto-routing` | Enable auto-routing feature |
| `--auto-routing-default-model` | Default model when no rule matches |

### LLM Provider API Keys
| Parameter | Provider |
|-----------|----------|
| `--dashscope-key` | Aliyun Dashscope (Qwen) |
| `--deepseek-key` | DeepSeek |
| `--moonshot-key` | Moonshot (Kimi) |
| `--zhipuai-key` | Zhipu AI |
| `--openai-key` | OpenAI |
| `--openrouter-key` | OpenRouter |
| `--claude-key` | Claude |
| `--gemini-key` | Google Gemini |
| `--groq-key` | Groq |
| `--doubao-key` | Doubao |
| `--baichuan-key` | Baichuan AI |
| `--yi-key` | 01.AI (Yi) |
| `--stepfun-key` | Stepfun |
| `--minimax-key` | Minimax |
| `--cohere-key` | Cohere |
| `--mistral-key` | Mistral AI |
| `--github-key` | Github Models |
| `--fireworks-key` | Fireworks AI |
| `--togetherai-key` | Together AI |
| `--grok-key` | Grok |

## Access Logs

After deployment, gateway access logs are available at:
```
$DATA_FOLDER/logs/access.log
```

These logs can be used with the **agent-session-monitor** skill for token tracking and conversation analysis.

## Managing Routing Rules

After deployment, use the `route` subcommand to manage auto-routing rules:

```bash
# Add a routing rule
./get-ai-gateway.sh route add --model claude-opus-4.5 --trigger "æ·±å…¥æ€è€ƒ|deep thinking"

# List all rules
./get-ai-gateway.sh route list

# Remove a rule
./get-ai-gateway.sh route remove --rule-id 0
```

See [higress-auto-router](../higress-auto-router/SKILL.md) for detailed documentation.

## Related Skills

This skill works with:

### higress-auto-router
Configure automatic model routing using CLI commands. Example:
```bash
./get-ai-gateway.sh route add --model claude-opus-4.5 --trigger "æ·±å…¥æ€è€ƒ|deep thinking"
```

See: [higress-auto-router](../higress-auto-router/SKILL.md)

### agent-session-monitor
Monitor and track token usage across sessions. Example:
- View session statistics in web UI
- Export FinOps reports
- Parse logs from `$DATA_FOLDER/logs/access.log`

See: [agent-session-monitor](../agent-session-monitor/SKILL.md)

## Examples

### Example 1: Basic Deployment with Dashscope

**User:** å¸®æˆ‘éƒ¨ç½²ä¸€ä¸ªHigress AIç½‘å…³ï¼Œä½¿ç”¨é˜¿é‡Œäº‘çš„é€šä¹‰åƒé—®

**Steps:**
1. Download script
2. Get Dashscope API key from user
3. Run:
   ```bash
   ./get-ai-gateway.sh start --non-interactive \
     --dashscope-key sk-xxx
   ```

**Response:**
```
âœ… Higress AI Gateway éƒ¨ç½²å®Œæˆï¼

ç½‘å…³åœ°å€: http://localhost:8080/v1/chat/completions
æ§åˆ¶å°: http://localhost:8001
æ—¥å¿—ç›®å½•: ./higress/logs

å·²é…ç½®çš„æ¨¡å‹æä¾›å•†:
- Aliyun Dashscope (Qwen)

æµ‹è¯•å‘½ä»¤:
curl 'http://localhost:8080/v1/chat/completions' \
  -H 'Content-Type: application/json' \
  -d '{"model": "qwen-turbo", "messages": [{"role": "user", "content": "Hello!"}]}'
```

### Example 2: Deployment with Auto-Routing

**User:** éƒ¨ç½²Higressç½‘å…³ï¼Œå¯ç”¨è‡ªåŠ¨è·¯ç”±ï¼Œé»˜è®¤ä½¿ç”¨qwen-turbo

**Steps:**
1. Download script
2. Get API keys
3. Run:
   ```bash
   ./get-ai-gateway.sh start --non-interactive \
     --dashscope-key sk-xxx \
     --auto-routing \
     --auto-routing-default-model qwen-turbo
   ```

**Response:**
```
âœ… Higress AI Gateway éƒ¨ç½²å®Œæˆï¼

ç½‘å…³åœ°å€: http://localhost:8080/v1/chat/completions
æ§åˆ¶å°: http://localhost:8001

ğŸ”€ è‡ªåŠ¨è·¯ç”±å·²å¯ç”¨:
- é»˜è®¤æ¨¡å‹: qwen-turbo
- ä½¿ç”¨ model="higress/auto" è§¦å‘è‡ªåŠ¨è·¯ç”±

æ·»åŠ è·¯ç”±è§„åˆ™:
./get-ai-gateway.sh route add --model claude-opus-4.5 --trigger "æ·±å…¥æ€è€ƒ|deep thinking"
```

### Example 3: Add Routing Rules

**User:** æˆ‘å¸Œæœ›åœ¨è§£å†³å›°éš¾é—®é¢˜æ—¶è·¯ç”±åˆ°claude-opus-4.5

**Steps:**
```bash
./get-ai-gateway.sh route add \
  --model claude-opus-4.5 \
  --trigger "æ·±å…¥æ€è€ƒ|deep thinking"
```

**Response:**
```
âœ… è·¯ç”±è§„åˆ™æ·»åŠ æˆåŠŸï¼

è§¦å‘æ–¹å¼ï¼šä»¥ "æ·±å…¥æ€è€ƒ" æˆ– "deep thinking" å¼€å¤´
ç›®æ ‡æ¨¡å‹ï¼šclaude-opus-4.5

ä½¿ç”¨ç¤ºä¾‹ï¼š
- æ·±å…¥æ€è€ƒ è¿™é“ç®—æ³•é¢˜åº”è¯¥æ€ä¹ˆè§£ï¼Ÿ
- deep thinking What's the best architecture for this system?
```

### Example 4: Full Integration with Clawdbot

**User:** å®Œæ•´é…ç½®Higresså’ŒClawdbotçš„é›†æˆ

**Steps:**
1. Deploy Higress AI Gateway
2. Configure Clawdbot provider
3. Enable auto-routing
4. Set up session monitoring

**Response:**
```
âœ… Higress AI Gateway é›†æˆå®Œæˆï¼

1. ç½‘å…³å·²éƒ¨ç½²:
   - HTTP: http://localhost:8080
   - Console: http://localhost:8001

2. Clawdbot é…ç½®:
   è¿è¡Œ `clawdbot models auth login --provider higress`

3. è‡ªåŠ¨è·¯ç”±:
   å·²å¯ç”¨ï¼Œä½¿ç”¨ model="higress/auto"

4. ä¼šè¯ç›‘æ§:
   æ—¥å¿—è·¯å¾„: ./higress/logs/access.log
   å¯åŠ¨ Web UI: python3 agent-session-monitor/scripts/webserver.py --data-dir ./sessions

éœ€è¦æˆ‘å¸®ä½ é…ç½®è‡ªåŠ¨è·¯ç”±è§„åˆ™å—ï¼Ÿ
```

## Troubleshooting

### Container fails to start
- Check Docker is running: `docker info`
- Check port availability: `netstat -tlnp | grep 8080`
- View container logs: `docker logs higress-ai-gateway`

### Gateway not responding
- Check container status: `docker ps -a`
- Verify port mapping: `docker port higress-ai-gateway`
- Test locally: `curl http://localhost:8080/v1/models`

### API key errors
- Verify the API key is correct
- Check provider documentation for key format
- Some providers require additional configuration (e.g., Azure, Bedrock)
