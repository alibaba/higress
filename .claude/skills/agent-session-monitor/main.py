#!/usr/bin/env python3
"""
Agent Session Monitor - å®æ—¶Agentå¯¹è¯è§‚æµ‹ç¨‹åº
ç›‘æ§Higressè®¿é—®æ—¥å¿—ï¼ŒæŒ‰sessionèšåˆå¯¹è¯ï¼Œè¿½è¸ªtokenå¼€é”€
"""

import argparse
import json
import re
import os
import sys
import time
from collections import defaultdict
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

try:
    from watchdog.observers import Observer
except ImportError:
    Observer = None
    print("Warning: watchdog not installed. Real-time file monitoring will be limited.", file=sys.stderr)

# ============================================================================
# é…ç½®
# ============================================================================

# Tokenå®šä»·ï¼ˆå•ä½ï¼šç¾å…ƒ/1M tokensï¼‰
TOKEN_PRICING = {
    "Qwen": {
        "input": 0.0002,  # $0.2/1M
        "output": 0.0006,
        "cached": 0.0001,  # cached tokensé€šå¸¸æ˜¯inputçš„50%
    },
    "Qwen3-rerank": {
        "input": 0.0003,
        "output": 0.0012,
        "cached": 0.00015,
    },
    "Qwen-Max": {
        "input": 0.0005,
        "output": 0.002,
        "cached": 0.00025,
    },
    "GPT-4": {
        "input": 0.003,
        "output": 0.006,
        "cached": 0.0015,
    },
    "GPT-4o": {
        "input": 0.0025,
        "output": 0.01,
        "cached": 0.00125,  # GPT-4o prompt caching: 50% discount
    },
    "GPT-4-32k": {
        "input": 0.01,
        "output": 0.03,
        "cached": 0.005,
    },
    "o1": {
        "input": 0.015,
        "output": 0.06,
        "cached": 0.0075,
        "reasoning": 0.06,  # o1 reasoning tokens same as output
    },
    "o1-mini": {
        "input": 0.003,
        "output": 0.012,
        "cached": 0.0015,
        "reasoning": 0.012,
    },
    "Claude": {
        "input": 0.015,
        "output": 0.075,
        "cached": 0.0015,  # Claude prompt caching: 90% discount
    },
    "DeepSeek-R1": {
        "input": 0.004,
        "output": 0.012,
        "reasoning": 0.002,
        "cached": 0.002,
    }
}

DEFAULT_LOG_PATH = "/var/log/higress/access.log"
DEFAULT_OUTPUT_DIR = "./sessions"

# ============================================================================
# Sessionç®¡ç†å™¨
# ============================================================================

class SessionManager:
    """ç®¡ç†å¤šä¸ªä¼šè¯çš„tokenç»Ÿè®¡"""
    
    def __init__(self, output_dir: str, load_existing: bool = True):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.sessions: Dict[str, dict] = {}
        
        # åŠ è½½å·²æœ‰çš„sessionæ•°æ®
        if load_existing:
            self._load_existing_sessions()
    
    def _load_existing_sessions(self):
        """åŠ è½½å·²æœ‰çš„sessionæ•°æ®"""
        loaded_count = 0
        for session_file in self.output_dir.glob("*.json"):
            try:
                with open(session_file, 'r', encoding='utf-8') as f:
                    session = json.load(f)
                    session_id = session.get('session_id')
                    if session_id:
                        self.sessions[session_id] = session
                        loaded_count += 1
            except Exception as e:
                print(f"Warning: Failed to load session {session_file}: {e}", file=sys.stderr)
        
        if loaded_count > 0:
            print(f"ğŸ“¦ Loaded {loaded_count} existing session(s)")
    
    def update_session(self, session_id: str, ai_log: dict) -> dict:
        """æ›´æ–°æˆ–åˆ›å»ºsession"""
        if session_id not in self.sessions:
            self.sessions[session_id] = {
                "session_id": session_id,
                "created_at": datetime.now().isoformat(),
                "updated_at": datetime.now().isoformat(),
                "messages_count": 0,
                "total_input_tokens": 0,
                "total_output_tokens": 0,
                "total_reasoning_tokens": 0,
                "total_cached_tokens": 0,
                "rounds": [],
                "model": ai_log.get("model", "unknown")
            }
        
        session = self.sessions[session_id]
        
        # æ›´æ–°ç»Ÿè®¡
        model = ai_log.get("model", "unknown")
        session["model"] = model
        session["updated_at"] = datetime.now().isoformat()
        
        # Tokenç»Ÿè®¡
        session["total_input_tokens"] += ai_log.get("input_token", 0)
        session["total_output_tokens"] += ai_log.get("output_token", 0)
        
        # æ£€æŸ¥reasoning tokensï¼ˆä¼˜å…ˆä½¿ç”¨ai_logä¸­çš„reasoning_tokenså­—æ®µï¼‰
        reasoning_tokens = ai_log.get("reasoning_tokens", 0)
        if reasoning_tokens == 0 and "reasoning" in ai_log and ai_log["reasoning"]:
            # å¦‚æœæ²¡æœ‰reasoning_tokenså­—æ®µï¼Œä¼°ç®—reasoningçš„tokenæ•°ï¼ˆå¤§è‡´æŒ‰å­—ç¬¦æ•°/4ï¼‰
            reasoning_text = ai_log["reasoning"]
            reasoning_tokens = len(reasoning_text) // 4
        session["total_reasoning_tokens"] += reasoning_tokens
        
        # æ£€æŸ¥cached tokensï¼ˆprompt cachingï¼‰
        cached_tokens = ai_log.get("cached_tokens", 0)
        session["total_cached_tokens"] += cached_tokens
        
        # æ£€æŸ¥æ˜¯å¦æœ‰tool_callsï¼ˆå·¥å…·è°ƒç”¨ï¼‰
        has_tool_calls = "tool_calls" in ai_log and ai_log["tool_calls"]
        
        # æ›´æ–°æ¶ˆæ¯æ•°
        session["messages_count"] += 1
        
        # è§£ætoken detailsï¼ˆå¦‚æœæœ‰ï¼‰
        input_token_details = {}
        output_token_details = {}
        
        if "input_token_details" in ai_log:
            try:
                # input_token_detailså¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
                details = ai_log["input_token_details"]
                if isinstance(details, str):
                    import json
                    input_token_details = json.loads(details)
                else:
                    input_token_details = details
            except (json.JSONDecodeError, TypeError):
                pass
        
        if "output_token_details" in ai_log:
            try:
                # output_token_detailså¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
                details = ai_log["output_token_details"]
                if isinstance(details, str):
                    import json
                    output_token_details = json.loads(details)
                else:
                    output_token_details = details
            except (json.JSONDecodeError, TypeError):
                pass
        
        # æ·»åŠ è½®æ¬¡è®°å½•ï¼ˆåŒ…å«å®Œæ•´çš„llmè¯·æ±‚å’Œå“åº”ä¿¡æ¯ï¼‰
        round_data = {
            "round": session["messages_count"],
            "timestamp": datetime.now().isoformat(),
            "input_tokens": ai_log.get("input_token", 0),
            "output_tokens": ai_log.get("output_token", 0),
            "reasoning_tokens": reasoning_tokens,
            "cached_tokens": cached_tokens,
            "model": model,
            "has_tool_calls": has_tool_calls,
            "response_type": ai_log.get("response_type", "normal"),
            # å®Œæ•´çš„å¯¹è¯ä¿¡æ¯
            "messages": ai_log.get("messages", []),
            "question": ai_log.get("question", ""),
            "answer": ai_log.get("answer", ""),
            "reasoning": ai_log.get("reasoning", ""),
            "tool_calls": ai_log.get("tool_calls", []),
            # Tokenè¯¦æƒ…
            "input_token_details": input_token_details,
            "output_token_details": output_token_details,
        }
        session["rounds"].append(round_data)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        self._save_session(session)
        
        return session
    
    def _save_session(self, session: dict):
        """ä¿å­˜sessionæ•°æ®åˆ°æ–‡ä»¶"""
        session_file = self.output_dir / f"{session['session_id']}.json"
        with open(session_file, 'w', encoding='utf-8') as f:
            json.dump(session, f, ensure_ascii=False, indent=2)
    
    def get_all_sessions(self) -> List[dict]:
        """è·å–æ‰€æœ‰session"""
        return list(self.sessions.values())
    
    def get_session(self, session_id: str) -> Optional[dict]:
        """è·å–æŒ‡å®šsession"""
        return self.sessions.get(session_id)
    
    def get_summary(self) -> dict:
        """è·å–æ€»ä½“ç»Ÿè®¡"""
        total_input = sum(s["total_input_tokens"] for s in self.sessions.values())
        total_output = sum(s["total_output_tokens"] for s in self.sessions.values())
        total_reasoning = sum(s.get("total_reasoning_tokens", 0) for s in self.sessions.values())
        total_cached = sum(s.get("total_cached_tokens", 0) for s in self.sessions.values())
        
        # è®¡ç®—æˆæœ¬
        total_cost = 0
        for session in self.sessions.values():
            model = session.get("model", "unknown")
            input_tokens = session["total_input_tokens"]
            output_tokens = session["total_output_tokens"]
            reasoning_tokens = session.get("total_reasoning_tokens", 0)
            cached_tokens = session.get("total_cached_tokens", 0)
            
            pricing = TOKEN_PRICING.get(model, TOKEN_PRICING.get("GPT-4", {}))
            
            # åŸºç¡€æˆæœ¬è®¡ç®—
            # æ³¨æ„ï¼šcached_tokenså·²ç»åŒ…å«åœ¨input_tokensä¸­ï¼Œéœ€è¦åˆ†å¼€è®¡ç®—
            regular_input_tokens = input_tokens - cached_tokens
            input_cost = regular_input_tokens * pricing.get("input", 0) / 1000000
            output_cost = output_tokens * pricing.get("output", 0) / 1000000
            
            # reasoningæˆæœ¬
            reasoning_cost = 0
            if "reasoning" in pricing and reasoning_tokens > 0:
                reasoning_cost = reasoning_tokens * pricing["reasoning"] / 1000000
            
            # cachedæˆæœ¬ï¼ˆé€šå¸¸æ¯”inputä¾¿å®œï¼‰
            cached_cost = 0
            if "cached" in pricing and cached_tokens > 0:
                cached_cost = cached_tokens * pricing["cached"] / 1000000
            
            total_cost += input_cost + output_cost + reasoning_cost + cached_cost
        
        return {
            "total_sessions": len(self.sessions),
            "total_input_tokens": total_input,
            "total_output_tokens": total_output,
            "total_reasoning_tokens": total_reasoning,
            "total_cached_tokens": total_cached,
            "total_tokens": total_input + total_output + total_reasoning + total_cached,
            "total_cost_usd": round(total_cost, 4),
            "active_session_ids": list(self.sessions.keys())
        }


# ============================================================================
# æ—¥å¿—è§£æå™¨
# ============================================================================

class LogParser:
    """è§£æHigressè®¿é—®æ—¥å¿—ï¼Œæå–ai_logï¼Œæ”¯æŒæ—¥å¿—è½®è½¬"""
    
    def __init__(self, state_file: str = None):
        self.state_file = Path(state_file) if state_file else None
        self.file_offsets = {}  # {æ–‡ä»¶è·¯å¾„: å·²è¯»å–çš„å­—èŠ‚åç§»}
        self._load_state()
    
    def _load_state(self):
        """åŠ è½½ä¸Šæ¬¡çš„è¯»å–çŠ¶æ€"""
        if self.state_file and self.state_file.exists():
            try:
                with open(self.state_file, 'r') as f:
                    self.file_offsets = json.load(f)
            except Exception as e:
                print(f"Warning: Failed to load state file: {e}", file=sys.stderr)
    
    def _save_state(self):
        """ä¿å­˜å½“å‰çš„è¯»å–çŠ¶æ€"""
        if self.state_file:
            try:
                self.state_file.parent.mkdir(parents=True, exist_ok=True)
                with open(self.state_file, 'w') as f:
                    json.dump(self.file_offsets, f, indent=2)
            except Exception as e:
                print(f"Warning: Failed to save state file: {e}", file=sys.stderr)
    
    def parse_log_line(self, line: str) -> Optional[dict]:
        """è§£æå•è¡Œæ—¥å¿—ï¼Œæå–ai_log JSON"""
        try:
            # ç›´æ¥è§£ææ•´ä¸ªæ—¥å¿—è¡Œä¸ºJSON
            log_obj = json.loads(line.strip())
            
            # è·å–ai_logå­—æ®µï¼ˆè¿™æ˜¯ä¸€ä¸ªJSONå­—ç¬¦ä¸²ï¼‰
            if 'ai_log' in log_obj:
                ai_log_str = log_obj['ai_log']
                
                # è§£æå†…å±‚JSON
                ai_log = json.loads(ai_log_str)
                return ai_log
        except (json.JSONDecodeError, ValueError, KeyError):
            # é™é»˜å¿½ç•¥éJSONè¡Œæˆ–ç¼ºå°‘ai_logå­—æ®µçš„è¡Œ
            pass
        
        return None
    
    def parse_rotated_logs(self, log_pattern: str, session_manager) -> None:
        """è§£ææ—¥å¿—æ–‡ä»¶åŠå…¶è½®è½¬æ–‡ä»¶
        
        Args:
            log_pattern: æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œå¦‚ /var/log/proxy/access.log
            session_manager: Sessionç®¡ç†å™¨
        """
        base_path = Path(log_pattern)
        
        # è‡ªåŠ¨æ‰«ææ‰€æœ‰è½®è½¬çš„æ—¥å¿—æ–‡ä»¶ï¼ˆä»æ—§åˆ°æ–°ï¼‰
        log_files = []
        
        # è‡ªåŠ¨æ‰«æè½®è½¬æ–‡ä»¶ï¼ˆæœ€å¤šæ‰«æåˆ° .100ï¼Œè¶…è¿‡è¿™ä¸ªæ•°é‡çš„æ—¥å¿—åº”è¯¥å¾ˆå°‘è§ï¼‰
        for i in range(100, 0, -1):
            rotated_path = Path(f"{log_pattern}.{i}")
            if rotated_path.exists():
                log_files.append(str(rotated_path))
        
        # æ·»åŠ å½“å‰æ—¥å¿—æ–‡ä»¶
        if base_path.exists():
            log_files.append(str(base_path))
        
        if not log_files:
            print(f"âŒ No log files found for pattern: {log_pattern}")
            return
        
        print(f"ğŸ“‚ Found {len(log_files)} log file(s):")
        for f in log_files:
            print(f"   - {f}")
        print()
        
        # æŒ‰é¡ºåºè§£ææ¯ä¸ªæ–‡ä»¶ï¼ˆä»æ—§åˆ°æ–°ï¼‰
        for log_file in log_files:
            self._parse_file_incremental(log_file, session_manager)
        
        # ä¿å­˜çŠ¶æ€
        self._save_state()
    
    def _parse_file_incremental(self, file_path: str, session_manager) -> None:
        """å¢é‡è§£æå•ä¸ªæ—¥å¿—æ–‡ä»¶"""
        try:
            file_stat = os.stat(file_path)
            file_size = file_stat.st_size
            file_inode = file_stat.st_ino
            
            # ä½¿ç”¨inodeä½œä¸ºä¸»é”®
            inode_key = str(file_inode)
            last_offset = self.file_offsets.get(inode_key, 0)
            
            # å¦‚æœæ–‡ä»¶å˜å°äº†ï¼Œè¯´æ˜æ˜¯æ–°æ–‡ä»¶ï¼ˆè¢«truncateæˆ–æ–°åˆ›å»ºï¼‰ï¼Œä»å¤´å¼€å§‹è¯»
            if file_size < last_offset:
                print(f"   ğŸ“ File truncated or recreated, reading from start: {file_path}")
                last_offset = 0
            
            # å¦‚æœoffsetç›¸åŒï¼Œè¯´æ˜æ²¡æœ‰æ–°å†…å®¹
            if file_size == last_offset:
                print(f"   â­ï¸  No new content in: {file_path} (inode:{inode_key})")
                return
            
            print(f"   ğŸ“– Reading {file_path} from offset {last_offset} to {file_size} (inode:{inode_key})")
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                f.seek(last_offset)
                lines_processed = 0
                
                for line in f:
                    ai_log = self.parse_log_line(line)
                    if ai_log:
                        session_id = ai_log.get("session_id", "default")
                        session_manager.update_session(session_id, ai_log)
                        lines_processed += 1
                        
                        # æ¯å¤„ç†1000è¡Œæ‰“å°ä¸€æ¬¡è¿›åº¦
                        if lines_processed % 1000 == 0:
                            print(f"      Processed {lines_processed} lines, {len(session_manager.sessions)} sessions")
                
                # æ›´æ–°offsetï¼ˆä½¿ç”¨inodeä½œä¸ºkeyï¼‰
                current_offset = f.tell()
                self.file_offsets[inode_key] = current_offset
                
                print(f"   âœ… Processed {lines_processed} new lines from {file_path}")
                
        except FileNotFoundError:
            print(f"   âŒ File not found: {file_path}")
        except Exception as e:
            print(f"   âŒ Error parsing {file_path}: {e}")


# ============================================================================
# å®æ—¶æ˜¾ç¤ºå™¨
# ============================================================================

class RealtimeMonitor:
    """å®æ—¶ç›‘æ§æ˜¾ç¤ºå’Œäº¤äº’ï¼ˆå®šæ—¶è½®è¯¢æ¨¡å¼ï¼‰"""
    
    def __init__(self, session_manager: SessionManager, log_parser=None, log_path: str = None, refresh_interval: int = 1):
        self.session_manager = session_manager
        self.log_parser = log_parser
        self.log_path = log_path
        self.refresh_interval = refresh_interval
        self.running = True
        self.last_poll_time = 0
    
    def start(self):
        """å¯åŠ¨å®æ—¶ç›‘æ§ï¼ˆå®šæ—¶è½®è¯¢æ—¥å¿—æ–‡ä»¶ï¼‰"""
        print(f"\n{'=' * 50}")
        print(f"ğŸ” Agent Session Monitor - Real-time View")
        print(f"{'=' * 50}")
        print()
        print("Press Ctrl+C to stop...")
        print()
        
        try:
            while self.running:
                # å®šæ—¶è½®è¯¢æ—¥å¿—æ–‡ä»¶ï¼ˆæ£€æŸ¥æ–°å¢å†…å®¹å’Œè½®è½¬ï¼‰
                current_time = time.time()
                if self.log_parser and self.log_path and (current_time - self.last_poll_time >= self.refresh_interval):
                    self.log_parser.parse_rotated_logs(self.log_path, self.session_manager)
                    self.last_poll_time = current_time
                
                # æ˜¾ç¤ºçŠ¶æ€
                self._display_status()
                time.sleep(self.refresh_interval)
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ Stopping monitor...")
            self.running = False
            self._display_summary()
    
    def _display_status(self):
        """æ˜¾ç¤ºå½“å‰çŠ¶æ€"""
        summary = self.session_manager.get_summary()
        
        # æ¸…å±
        os.system('clear' if os.name == 'posix' else 'cls')
        
        print(f"{'=' * 50}")
        print(f"ğŸ” Session Monitor - Active")
        print(f"{'=' * 50}")
        print()
        print(f"ğŸ“Š Active Sessions: {summary['total_sessions']}")
        print()
        
        # æ˜¾ç¤ºæ´»è·ƒsessionçš„tokenç»Ÿè®¡
        if summary['active_session_ids']:
            print("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print("â”‚ Session ID               â”‚ Msgs    â”‚ Input    â”‚ Output    â”‚")
            print("â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
            
            for session_id in summary['active_session_ids'][:10]:  # æœ€å¤šæ˜¾ç¤º10ä¸ª
                session = self.session_manager.get_session(session_id)
                if session:
                    sid = session_id[:24] if len(session_id) > 24 else session_id
                    print(f"â”‚ {sid:<24} â”‚ {session['messages_count']:>7} â”‚ {session['total_input_tokens']:>8,} â”‚ {session['total_output_tokens']:>9,} â”‚")
            
            print("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
        
        print()
        print(f"ğŸ“ˆ Token Statistics")
        print(f"   Total Input:   {summary['total_input_tokens']:,} tokens")
        print(f"   Total Output:  {summary['total_output_tokens']:,} tokens")
        if summary['total_reasoning_tokens'] > 0:
            print(f"   Total Reasoning: {summary['total_reasoning_tokens']:,} tokens")
        print(f"   Total Cached:   {summary['total_cached_tokens']:,} tokens")
        print(f"   Total Cost:     ${summary['total_cost_usd']:.4f}")
    
    def _display_summary(self):
        """æ˜¾ç¤ºæœ€ç»ˆæ±‡æ€»"""
        summary = self.session_manager.get_summary()
        
        print()
        print(f"{'=' * 50}")
        print(f"ğŸ“Š Session Monitor - Summary")
        print(f"{'=' * 50}")
        print()
        print(f"ğŸ“ˆ Final Statistics")
        print(f"   Total Sessions: {summary['total_sessions']}")
        print(f"   Total Input:   {summary['total_input_tokens']:,} tokens")
        print(f"   Total Output:  {summary['total_output_tokens']:,} tokens")
        if summary['total_reasoning_tokens'] > 0:
            print(f"   Total Reasoning: {summary['total_reasoning_tokens']:,} tokens")
        print(f"   Total Cached:   {summary['total_cached_tokens']:,} tokens")
        print(f"   Total Tokens:   {summary['total_tokens']:,} tokens")
        print(f"   Total Cost:     ${summary['total_cost_usd']:.4f}")
        print(f"{'=' * 50}")
        print()


# ============================================================================
# æ–‡ä»¶ç›‘æ§å™¨ï¼ˆå¦‚æœwatchdogå¯ç”¨ï¼‰
# ============================================================================

class LogFileWatcher:
    """ç›‘æ§æ—¥å¿—æ–‡ä»¶å˜åŒ–ï¼Œå¢é‡è§£æ"""
    
    def __init__(self, log_path: str, session_manager: SessionManager):
        self.log_path = Path(log_path)
        self.session_manager = session_manager
        self.last_size = 0
        if self.log_path.exists():
            self.last_size = self.log_path.stat().st_size
    
    def on_modified(self, event):
        """æ–‡ä»¶ä¿®æ”¹äº‹ä»¶å¤„ç†"""
        if event.src_path != self.log_path:
            return
        
        # è¯»å–æ–°å¢å†…å®¹
        new_size = event.src_path.stat().st_size
        if new_size <= self.last_size:
            return
        
        try:
            with open(event.src_path, 'r', encoding='utf-8') as f:
                f.seek(self.last_size)
                new_lines = f.readlines()
            
            self.last_size = new_size
            
            # è§£ææ–°å¢çš„æ—¥å¿—
            for line in new_lines:
                ai_log = self.parse_log_line(line)
                if ai_log:
                    session_id = ai_log.get("session_id", "default")
                    session_manager.update_session(session_id, ai_log)
            
            print(f"ğŸ“ Processed {len(new_lines)} new log lines, {len(session_manager.sessions)} sessions")
            
        except Exception as e:
            print(f"âŒ Error processing log changes: {e}", file=sys.stderr)


# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="Agent Session Monitor - å®æ—¶ç›‘æ§å¤šè½®Agentå¯¹è¯çš„tokenå¼€é”€",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # ç›‘æ§é»˜è®¤æ—¥å¿—
  %(prog)s
  
  # ç›‘æ§æŒ‡å®šæ—¥å¿—æ–‡ä»¶
  %(prog)s --log-path /var/log/higress/access.log
  
  # è®¾ç½®é¢„ç®—ä¸º500K tokens
  %(prog)s --budget 500000
  
  # ç›‘æ§ç‰¹å®šsession
  %(prog)s --session-key agent:main:discord:channel:1465367993012981988
        """,
        allow_abbrev=False
    )
    
    parser.add_argument(
        '--log-path',
        default=DEFAULT_LOG_PATH,
        help=f'Higressè®¿é—®æ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: {DEFAULT_LOG_PATH}ï¼‰'
    )
    
    parser.add_argument(
        '--output-dir',
        default=DEFAULT_OUTPUT_DIR,
        help=f'Sessionæ•°æ®å­˜å‚¨ç›®å½•ï¼ˆé»˜è®¤: {DEFAULT_OUTPUT_DIR}ï¼‰'
    )
    
    parser.add_argument(
        '--session-key',
        help='åªç›‘æ§åŒ…å«æŒ‡å®šsession keyçš„æ—¥å¿—'
    )
    
    parser.add_argument(
        '--refresh-interval',
        type=int,
        default=1,
        help=f'å®æ—¶ç›‘æ§åˆ·æ–°é—´éš”ï¼ˆç§’ï¼Œé»˜è®¤: 1ï¼‰'
    )
    
    parser.add_argument(
        '--state-file',
        help='çŠ¶æ€æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºè®°å½•å·²è¯»å–çš„offsetï¼ˆé»˜è®¤: <output-dir>/.state.jsonï¼‰'
    )
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–ç»„ä»¶
    session_manager = SessionManager(output_dir=args.output_dir)
    
    # çŠ¶æ€æ–‡ä»¶è·¯å¾„
    state_file = args.state_file or str(Path(args.output_dir) / '.state.json')
    
    log_parser = LogParser(state_file=state_file)
    
    print(f"{'=' * 60}")
    print(f"ğŸ” Agent Session Monitor")
    print(f"{'=' * 60}")
    print()
    print(f"ğŸ“‚ Log path: {args.log_path}")
    print(f"ğŸ“ Output dir: {args.output_dir}")
    if args.session_key:
        print(f"ğŸ”‘ Session key filter: {args.session_key}")
    print(f"{'=' * 60}")
    print()
    
    # æ¨¡å¼é€‰æ‹©ï¼šå®æ—¶ç›‘æ§æˆ–å•æ¬¡è§£æ
    if len(sys.argv) == 1:
        # é»˜è®¤æ¨¡å¼ï¼šå®æ—¶ç›‘æ§ï¼ˆå®šæ—¶è½®è¯¢ï¼‰
        print("ğŸ“º Mode: Real-time monitoring (polling mode with log rotation support)")
        print(f"   Refresh interval: {args.refresh_interval} second(s)")
        print()
        
        # é¦–æ¬¡è§£æç°æœ‰æ—¥å¿—æ–‡ä»¶ï¼ˆåŒ…æ‹¬è½®è½¬çš„æ–‡ä»¶ï¼‰
        log_parser.parse_rotated_logs(args.log_path, session_manager)
        
        # å¯åŠ¨å®æ—¶ç›‘æ§ï¼ˆå®šæ—¶è½®è¯¢æ¨¡å¼ï¼‰
        monitor = RealtimeMonitor(
            session_manager, 
            log_parser=log_parser,
            log_path=args.log_path,
            refresh_interval=args.refresh_interval
        )
        monitor.start()
        
    else:
        # å•æ¬¡è§£ææ¨¡å¼
        print("ğŸ“Š Mode: One-time log parsing (with log rotation support)")
        print()
        log_parser.parse_rotated_logs(args.log_path, session_manager)
        
        # æ˜¾ç¤ºæ±‡æ€»
        summary = session_manager.get_summary()
        print(f"\n{'=' * 50}")
        print(f"ğŸ“Š Session Summary")
        print(f"{'=' * 50}")
        print()
        print(f"ğŸ“ˆ Final Statistics")
        print(f"   Total Sessions: {summary['total_sessions']}")
        print(f"   Total Input:   {summary['total_input_tokens']:,} tokens")
        print(f"   Total Output:  {summary['total_output_tokens']:,} tokens")
        if summary['total_reasoning_tokens'] > 0:
            print(f"   Total Reasoning: {summary['total_reasoning_tokens']:,} tokens")
        print(f"   Total Cached:   {summary['total_cached_tokens']:,} tokens")
        print(f"   Total Tokens:   {summary['total_tokens']:,} tokens")
        print(f"   Total Cost:     ${summary['total_cost_usd']:.4f}")
        print(f"{'=' * 50}")
        print()
        print(f"ğŸ’¾ Session data saved to: {args.output_dir}/")
        print(f"   Run with --output-dir to specify custom directory")


if __name__ == '__main__':
    main()
