#!/usr/bin/env python3
"""
Agent Session Monitor CLI - æŸ¥è¯¢å’Œåˆ†æagentå¯¹è¯æ•°æ®
æ”¯æŒï¼š
1. å®æ—¶æŸ¥è¯¢æŒ‡å®šsessionçš„å®Œæ•´llmè¯·æ±‚å’Œå“åº”
2. æŒ‰æ¨¡å‹ç»Ÿè®¡tokenå¼€é”€
3. æŒ‰æ—¥æœŸç»Ÿè®¡tokenå¼€é”€
4. ç”ŸæˆFinOpsæŠ¥è¡¨
"""

import argparse
import json
import sys
from collections import defaultdict
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import re

# Tokenå®šä»·ï¼ˆå•ä½ï¼šç¾å…ƒ/1M tokensï¼‰
TOKEN_PRICING = {
    "Qwen": {
        "input": 0.0002,  # $0.2/1M
        "output": 0.0006,
        "cached": 0.0001,  # cached tokensé€šå¸¸æ˜¯inputçš„50%
    },
    "Qwen3-rerank": {
        "input": 0.0003,
        "output": 0.0012,
        "cached": 0.00015,
    },
    "Qwen-Max": {
        "input": 0.0005,
        "output": 0.002,
        "cached": 0.00025,
    },
    "GPT-4": {
        "input": 0.003,
        "output": 0.006,
        "cached": 0.0015,
    },
    "GPT-4o": {
        "input": 0.0025,
        "output": 0.01,
        "cached": 0.00125,  # GPT-4o prompt caching: 50% discount
    },
    "GPT-4-32k": {
        "input": 0.01,
        "output": 0.03,
        "cached": 0.005,
    },
    "o1": {
        "input": 0.015,
        "output": 0.06,
        "cached": 0.0075,
        "reasoning": 0.06,  # o1 reasoning tokens same as output
    },
    "o1-mini": {
        "input": 0.003,
        "output": 0.012,
        "cached": 0.0015,
        "reasoning": 0.012,
    },
    "Claude": {
        "input": 0.015,
        "output": 0.075,
        "cached": 0.0015,  # Claude prompt caching: 90% discount
    },
    "DeepSeek-R1": {
        "input": 0.004,
        "output": 0.012,
        "reasoning": 0.002,
        "cached": 0.002,
    }
}


class SessionAnalyzer:
    """Sessionæ•°æ®åˆ†æå™¨"""
    
    def __init__(self, data_dir: str):
        self.data_dir = Path(data_dir)
        if not self.data_dir.exists():
            raise FileNotFoundError(f"Session data directory not found: {data_dir}")
    
    def load_session(self, session_id: str) -> Optional[dict]:
        """åŠ è½½æŒ‡å®šsessionçš„å®Œæ•´æ•°æ®"""
        session_file = self.data_dir / f"{session_id}.json"
        if not session_file.exists():
            return None
        
        with open(session_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def load_all_sessions(self) -> List[dict]:
        """åŠ è½½æ‰€æœ‰sessionæ•°æ®"""
        sessions = []
        for session_file in self.data_dir.glob("*.json"):
            try:
                with open(session_file, 'r', encoding='utf-8') as f:
                    session = json.load(f)
                    sessions.append(session)
            except Exception as e:
                print(f"Warning: Failed to load {session_file}: {e}", file=sys.stderr)
        return sessions
    
    def display_session_detail(self, session_id: str, show_messages: bool = True):
        """æ˜¾ç¤ºsessionçš„è¯¦ç»†ä¿¡æ¯"""
        session = self.load_session(session_id)
        if not session:
            print(f"âŒ Session not found: {session_id}")
            return
        
        print(f"\n{'='*70}")
        print(f"ğŸ“Š Session Detail: {session_id}")
        print(f"{'='*70}\n")
        
        # åŸºæœ¬ä¿¡æ¯
        print(f"ğŸ• Created:  {session['created_at']}")
        print(f"ğŸ•‘ Updated:  {session['updated_at']}")
        print(f"ğŸ¤– Model:    {session['model']}")
        print(f"ğŸ’¬ Messages: {session['messages_count']}")
        print()
        
        # Tokenç»Ÿè®¡
        print(f"ğŸ“ˆ Token Statistics:")
        
        total_input = session['total_input_tokens']
        total_output = session['total_output_tokens']
        total_reasoning = session.get('total_reasoning_tokens', 0)
        total_cached = session.get('total_cached_tokens', 0)
        
        # åŒºåˆ†regular inputå’Œcached input
        regular_input = total_input - total_cached
        
        if total_cached > 0:
            print(f"   Input:      {regular_input:>10,} tokens (regular)")
            print(f"   Cached:     {total_cached:>10,} tokens (from cache)")
            print(f"   Total Input:{total_input:>10,} tokens")
        else:
            print(f"   Input:      {total_input:>10,} tokens")
        
        print(f"   Output:     {total_output:>10,} tokens")
        
        if total_reasoning > 0:
            print(f"   Reasoning:  {total_reasoning:>10,} tokens")
        
        # æ€»è®¡ï¼ˆä¸é‡å¤è®¡ç®—cachedï¼‰
        total_tokens = total_input + total_output + total_reasoning
        print(f"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
        print(f"   Total:      {total_tokens:>10,} tokens")
        print()
        
        # æˆæœ¬è®¡ç®—
        cost = self._calculate_cost(session)
        print(f"ğŸ’° Estimated Cost: ${cost:.8f} USD")
        print()
        
        # å¯¹è¯è½®æ¬¡
        if show_messages and 'rounds' in session:
            print(f"ğŸ“ Conversation Rounds ({len(session['rounds'])}):")
            print(f"{'â”€'*70}")
            
            for i, round_data in enumerate(session['rounds'], 1):
                timestamp = round_data.get('timestamp', 'N/A')
                input_tokens = round_data.get('input_tokens', 0)
                output_tokens = round_data.get('output_tokens', 0)
                has_tool_calls = round_data.get('has_tool_calls', False)
                response_type = round_data.get('response_type', 'normal')
                
                print(f"\n  Round {i} @ {timestamp}")
                print(f"    Tokens: {input_tokens:,} in â†’ {output_tokens:,} out")
                
                if has_tool_calls:
                    print(f"    ğŸ”§ Tool calls: Yes")
                
                if response_type != 'normal':
                    print(f"    Type: {response_type}")
                
                # æ˜¾ç¤ºå®Œæ•´çš„messagesï¼ˆå¦‚æœæœ‰ï¼‰
                if 'messages' in round_data:
                    messages = round_data['messages']
                    print(f"    Messages ({len(messages)}):")
                    for msg in messages[-3:]:  # åªæ˜¾ç¤ºæœ€å3æ¡
                        role = msg.get('role', 'unknown')
                        content = msg.get('content', '')
                        content_preview = content[:100] + '...' if len(content) > 100 else content
                        print(f"      [{role}] {content_preview}")
                
                # æ˜¾ç¤ºquestion/answer/reasoningï¼ˆå¦‚æœæœ‰ï¼‰
                if 'question' in round_data:
                    q = round_data['question']
                    q_preview = q[:150] + '...' if len(q) > 150 else q
                    print(f"    â“ Question: {q_preview}")
                
                if 'answer' in round_data:
                    a = round_data['answer']
                    a_preview = a[:150] + '...' if len(a) > 150 else a
                    print(f"    âœ… Answer: {a_preview}")
                
                if 'reasoning' in round_data and round_data['reasoning']:
                    r = round_data['reasoning']
                    r_preview = r[:150] + '...' if len(r) > 150 else r
                    print(f"    ğŸ§  Reasoning: {r_preview}")
                
                if 'tool_calls' in round_data and round_data['tool_calls']:
                    print(f"    ğŸ› ï¸  Tool Calls:")
                    for tool_call in round_data['tool_calls']:
                        func_name = tool_call.get('function', {}).get('name', 'unknown')
                        args = tool_call.get('function', {}).get('arguments', '')
                        print(f"       - {func_name}({args[:80]}...)")
                
                # æ˜¾ç¤ºtoken detailsï¼ˆå¦‚æœæœ‰ï¼‰
                if round_data.get('input_token_details'):
                    print(f"    ğŸ“Š Input Token Details: {round_data['input_token_details']}")
                
                if round_data.get('output_token_details'):
                    print(f"    ğŸ“Š Output Token Details: {round_data['output_token_details']}")
            
            print(f"\n{'â”€'*70}")
        
        print(f"\n{'='*70}\n")
    
    def _calculate_cost(self, session: dict) -> float:
        """è®¡ç®—sessionçš„æˆæœ¬"""
        model = session.get('model', 'unknown')
        pricing = TOKEN_PRICING.get(model, TOKEN_PRICING.get("GPT-4", {}))
        
        input_tokens = session['total_input_tokens']
        output_tokens = session['total_output_tokens']
        reasoning_tokens = session.get('total_reasoning_tokens', 0)
        cached_tokens = session.get('total_cached_tokens', 0)
        
        # åŒºåˆ†regular inputå’Œcached input
        regular_input_tokens = input_tokens - cached_tokens
        
        input_cost = regular_input_tokens * pricing.get('input', 0) / 1000000
        output_cost = output_tokens * pricing.get('output', 0) / 1000000
        
        reasoning_cost = 0
        if 'reasoning' in pricing and reasoning_tokens > 0:
            reasoning_cost = reasoning_tokens * pricing['reasoning'] / 1000000
        
        cached_cost = 0
        if 'cached' in pricing and cached_tokens > 0:
            cached_cost = cached_tokens * pricing['cached'] / 1000000
        
        return input_cost + output_cost + reasoning_cost + cached_cost
    
    def stats_by_model(self) -> Dict[str, dict]:
        """æŒ‰æ¨¡å‹ç»Ÿè®¡tokenå¼€é”€"""
        sessions = self.load_all_sessions()
        
        stats = defaultdict(lambda: {
            'session_count': 0,
            'total_input': 0,
            'total_output': 0,
            'total_reasoning': 0,
            'total_cost': 0.0
        })
        
        for session in sessions:
            model = session.get('model', 'unknown')
            stats[model]['session_count'] += 1
            stats[model]['total_input'] += session['total_input_tokens']
            stats[model]['total_output'] += session['total_output_tokens']
            stats[model]['total_reasoning'] += session.get('total_reasoning_tokens', 0)
            stats[model]['total_cost'] += self._calculate_cost(session)
        
        return dict(stats)
    
    def stats_by_date(self, days: int = 30) -> Dict[str, dict]:
        """æŒ‰æ—¥æœŸç»Ÿè®¡tokenå¼€é”€ï¼ˆæœ€è¿‘Nå¤©ï¼‰"""
        sessions = self.load_all_sessions()
        
        stats = defaultdict(lambda: {
            'session_count': 0,
            'total_input': 0,
            'total_output': 0,
            'total_reasoning': 0,
            'total_cost': 0.0,
            'models': set()
        })
        
        cutoff_date = datetime.now() - timedelta(days=days)
        
        for session in sessions:
            created_at = datetime.fromisoformat(session['created_at'])
            if created_at < cutoff_date:
                continue
            
            date_key = created_at.strftime('%Y-%m-%d')
            stats[date_key]['session_count'] += 1
            stats[date_key]['total_input'] += session['total_input_tokens']
            stats[date_key]['total_output'] += session['total_output_tokens']
            stats[date_key]['total_reasoning'] += session.get('total_reasoning_tokens', 0)
            stats[date_key]['total_cost'] += self._calculate_cost(session)
            stats[date_key]['models'].add(session.get('model', 'unknown'))
        
        # è½¬æ¢setsä¸ºlistsä»¥ä¾¿JSONåºåˆ—åŒ–
        for date_key in stats:
            stats[date_key]['models'] = list(stats[date_key]['models'])
        
        return dict(stats)
    
    def display_model_stats(self):
        """æ˜¾ç¤ºæŒ‰æ¨¡å‹çš„ç»Ÿè®¡"""
        stats = self.stats_by_model()
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š Statistics by Model")
        print(f"{'='*80}\n")
        
        print(f"{'Model':<20} {'Sessions':<10} {'Input':<15} {'Output':<15} {'Cost (USD)':<12}")
        print(f"{'â”€'*80}")
        
        # æŒ‰æˆæœ¬é™åºæ’åˆ—
        sorted_models = sorted(stats.items(), key=lambda x: x[1]['total_cost'], reverse=True)
        
        for model, data in sorted_models:
            print(f"{model:<20} "
                  f"{data['session_count']:<10} "
                  f"{data['total_input']:>12,}  "
                  f"{data['total_output']:>12,}  "
                  f"${data['total_cost']:>10.6f}")
        
        # æ€»è®¡
        total_sessions = sum(d['session_count'] for d in stats.values())
        total_input = sum(d['total_input'] for d in stats.values())
        total_output = sum(d['total_output'] for d in stats.values())
        total_cost = sum(d['total_cost'] for d in stats.values())
        
        print(f"{'â”€'*80}")
        print(f"{'TOTAL':<20} "
              f"{total_sessions:<10} "
              f"{total_input:>12,}  "
              f"{total_output:>12,}  "
              f"${total_cost:>10.6f}")
        
        print(f"\n{'='*80}\n")
    
    def display_date_stats(self, days: int = 30):
        """æ˜¾ç¤ºæŒ‰æ—¥æœŸçš„ç»Ÿè®¡"""
        stats = self.stats_by_date(days)
        
        print(f"\n{'='*80}")
        print(f"ğŸ“Š Statistics by Date (Last {days} days)")
        print(f"{'='*80}\n")
        
        print(f"{'Date':<12} {'Sessions':<10} {'Input':<15} {'Output':<15} {'Cost (USD)':<12} {'Models':<20}")
        print(f"{'â”€'*80}")
        
        # æŒ‰æ—¥æœŸå‡åºæ’åˆ—
        sorted_dates = sorted(stats.items())
        
        for date, data in sorted_dates:
            models_str = ', '.join(data['models'][:3])  # æœ€å¤šæ˜¾ç¤º3ä¸ªæ¨¡å‹
            if len(data['models']) > 3:
                models_str += f" +{len(data['models'])-3}"
            
            print(f"{date:<12} "
                  f"{data['session_count']:<10} "
                  f"{data['total_input']:>12,}  "
                  f"{data['total_output']:>12,}  "
                  f"${data['total_cost']:>10.4f}  "
                  f"{models_str}")
        
        # æ€»è®¡
        total_sessions = sum(d['session_count'] for d in stats.values())
        total_input = sum(d['total_input'] for d in stats.values())
        total_output = sum(d['total_output'] for d in stats.values())
        total_cost = sum(d['total_cost'] for d in stats.values())
        
        print(f"{'â”€'*80}")
        print(f"{'TOTAL':<12} "
              f"{total_sessions:<10} "
              f"{total_input:>12,}  "
              f"{total_output:>12,}  "
              f"${total_cost:>10.4f}")
        
        print(f"\n{'='*80}\n")
    
    def list_sessions(self, limit: int = 20, sort_by: str = 'updated'):
        """åˆ—å‡ºæ‰€æœ‰session"""
        sessions = self.load_all_sessions()
        
        # æ’åº
        if sort_by == 'updated':
            sessions.sort(key=lambda s: s.get('updated_at', ''), reverse=True)
        elif sort_by == 'cost':
            sessions.sort(key=lambda s: self._calculate_cost(s), reverse=True)
        elif sort_by == 'tokens':
            sessions.sort(key=lambda s: s['total_input_tokens'] + s['total_output_tokens'], reverse=True)
        
        print(f"\n{'='*100}")
        print(f"ğŸ“‹ Sessions (sorted by {sort_by}, showing {min(limit, len(sessions))} of {len(sessions)})")
        print(f"{'='*100}\n")
        
        print(f"{'Session ID':<30} {'Updated':<20} {'Model':<15} {'Msgs':<6} {'Tokens':<12} {'Cost':<10}")
        print(f"{'â”€'*100}")
        
        for session in sessions[:limit]:
            session_id = session['session_id'][:28] + '..' if len(session['session_id']) > 30 else session['session_id']
            updated = session.get('updated_at', 'N/A')[:19]
            model = session.get('model', 'unknown')[:13]
            msg_count = session.get('messages_count', 0)
            total_tokens = session['total_input_tokens'] + session['total_output_tokens']
            cost = self._calculate_cost(session)
            
            print(f"{session_id:<30} {updated:<20} {model:<15} {msg_count:<6} {total_tokens:>10,}  ${cost:>8.4f}")
        
        print(f"\n{'='*100}\n")
    
    def export_finops_report(self, output_file: str, format: str = 'json'):
        """å¯¼å‡ºFinOpsæŠ¥è¡¨"""
        model_stats = self.stats_by_model()
        date_stats = self.stats_by_date(30)
        
        report = {
            'generated_at': datetime.now().isoformat(),
            'summary': {
                'total_sessions': sum(d['session_count'] for d in model_stats.values()),
                'total_input_tokens': sum(d['total_input'] for d in model_stats.values()),
                'total_output_tokens': sum(d['total_output'] for d in model_stats.values()),
                'total_cost_usd': sum(d['total_cost'] for d in model_stats.values()),
            },
            'by_model': model_stats,
            'by_date': date_stats,
        }
        
        output_path = Path(output_file)
        
        if format == 'json':
            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=2)
            print(f"âœ… FinOps report exported to: {output_path}")
        
        elif format == 'csv':
            import csv
            
            # æŒ‰æ¨¡å‹å¯¼å‡ºCSV
            model_csv = output_path.with_suffix('.model.csv')
            with open(model_csv, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['Model', 'Sessions', 'Input Tokens', 'Output Tokens', 'Cost (USD)'])
                for model, data in model_stats.items():
                    writer.writerow([
                        model,
                        data['session_count'],
                        data['total_input'],
                        data['total_output'],
                        f"{data['total_cost']:.6f}"
                    ])
            
            # æŒ‰æ—¥æœŸå¯¼å‡ºCSV
            date_csv = output_path.with_suffix('.date.csv')
            with open(date_csv, 'w', newline='', encoding='utf-8') as f:
                writer = csv.writer(f)
                writer.writerow(['Date', 'Sessions', 'Input Tokens', 'Output Tokens', 'Cost (USD)', 'Models'])
                for date, data in sorted(date_stats.items()):
                    writer.writerow([
                        date,
                        data['session_count'],
                        data['total_input'],
                        data['total_output'],
                        f"{data['total_cost']:.6f}",
                        ', '.join(data['models'])
                    ])
            
            print(f"âœ… FinOps report exported to:")
            print(f"   Model stats: {model_csv}")
            print(f"   Date stats:  {date_csv}")


def main():
    parser = argparse.ArgumentParser(
        description="Agent Session Monitor CLI - æŸ¥è¯¢å’Œåˆ†æagentå¯¹è¯æ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Commands:
  show <session-id>      æ˜¾ç¤ºsessionçš„è¯¦ç»†ä¿¡æ¯
  list                   åˆ—å‡ºæ‰€æœ‰session
  stats-model            æŒ‰æ¨¡å‹ç»Ÿè®¡tokenå¼€é”€
  stats-date             æŒ‰æ—¥æœŸç»Ÿè®¡tokenå¼€é”€ï¼ˆé»˜è®¤30å¤©ï¼‰
  export                 å¯¼å‡ºFinOpsæŠ¥è¡¨

Examples:
  # æŸ¥çœ‹ç‰¹å®šsessionçš„è¯¦ç»†å¯¹è¯
  %(prog)s show agent:main:discord:channel:1465367993012981988
  
  # åˆ—å‡ºæœ€è¿‘20ä¸ªsessionï¼ˆæŒ‰æ›´æ–°æ—¶é—´ï¼‰
  %(prog)s list
  
  # åˆ—å‡ºtokenå¼€é”€æœ€é«˜çš„10ä¸ªsession
  %(prog)s list --sort-by cost --limit 10
  
  # æŒ‰æ¨¡å‹ç»Ÿè®¡tokenå¼€é”€
  %(prog)s stats-model
  
  # æŒ‰æ—¥æœŸç»Ÿè®¡tokenå¼€é”€ï¼ˆæœ€è¿‘7å¤©ï¼‰
  %(prog)s stats-date --days 7
  
  # å¯¼å‡ºFinOpsæŠ¥è¡¨ï¼ˆJSONæ ¼å¼ï¼‰
  %(prog)s export finops-report.json
  
  # å¯¼å‡ºFinOpsæŠ¥è¡¨ï¼ˆCSVæ ¼å¼ï¼‰
  %(prog)s export finops-report --format csv
        """
    )
    
    parser.add_argument(
        'command',
        choices=['show', 'list', 'stats-model', 'stats-date', 'export'],
        help='å‘½ä»¤'
    )
    
    parser.add_argument(
        'args',
        nargs='*',
        help='å‘½ä»¤å‚æ•°ï¼ˆä¾‹å¦‚ï¼šsession-idæˆ–è¾“å‡ºæ–‡ä»¶åï¼‰'
    )
    
    parser.add_argument(
        '--data-dir',
        default='./sessions',
        help='Sessionæ•°æ®ç›®å½•ï¼ˆé»˜è®¤: ./sessionsï¼‰'
    )
    
    parser.add_argument(
        '--limit',
        type=int,
        default=20,
        help='listå‘½ä»¤çš„ç»“æœé™åˆ¶ï¼ˆé»˜è®¤: 20ï¼‰'
    )
    
    parser.add_argument(
        '--sort-by',
        choices=['updated', 'cost', 'tokens'],
        default='updated',
        help='listå‘½ä»¤çš„æ’åºæ–¹å¼ï¼ˆé»˜è®¤: updatedï¼‰'
    )
    
    parser.add_argument(
        '--days',
        type=int,
        default=30,
        help='stats-dateå‘½ä»¤çš„å¤©æ•°ï¼ˆé»˜è®¤: 30ï¼‰'
    )
    
    parser.add_argument(
        '--format',
        choices=['json', 'csv'],
        default='json',
        help='exportå‘½ä»¤çš„è¾“å‡ºæ ¼å¼ï¼ˆé»˜è®¤: jsonï¼‰'
    )
    
    parser.add_argument(
        '--no-messages',
        action='store_true',
        help='showå‘½ä»¤ï¼šä¸æ˜¾ç¤ºå¯¹è¯å†…å®¹'
    )
    
    args = parser.parse_args()
    
    try:
        analyzer = SessionAnalyzer(args.data_dir)
        
        if args.command == 'show':
            if not args.args:
                parser.error("showå‘½ä»¤éœ€è¦session-idå‚æ•°")
            session_id = args.args[0]
            analyzer.display_session_detail(session_id, show_messages=not args.no_messages)
        
        elif args.command == 'list':
            analyzer.list_sessions(limit=args.limit, sort_by=args.sort_by)
        
        elif args.command == 'stats-model':
            analyzer.display_model_stats()
        
        elif args.command == 'stats-date':
            analyzer.display_date_stats(days=args.days)
        
        elif args.command == 'export':
            if not args.args:
                parser.error("exportå‘½ä»¤éœ€è¦è¾“å‡ºæ–‡ä»¶åå‚æ•°")
            output_file = args.args[0]
            analyzer.export_finops_report(output_file, format=args.format)
    
    except FileNotFoundError as e:
        print(f"âŒ Error: {e}", file=sys.stderr)
        sys.exit(1)
    except Exception as e:
        print(f"âŒ Unexpected error: {e}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
